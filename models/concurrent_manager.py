import asyncio
import threading
import time
import os
import subprocess
from typing import Dict, List, Optional, Any, Tuple
from concurrent.futures import ThreadPoolExecutor
import logging
from queue import Queue, Empty, PriorityQueue
from dataclasses import dataclass, field
from .base import BaseModel
from .flux_model import FluxModel
from device_manager import DeviceManager
from config import Config
import uuid
import torch

logger = logging.getLogger(__name__)

@dataclass
class GenerationTask:
    """ç”Ÿæˆä»»åŠ¡"""
    task_id: str
    model_id: str
    prompt: str
    params: Dict[str, Any]
    result_queue: Queue
    created_at: float
    priority: int = 0  # ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    
    def __lt__(self, other):
        """æ”¯æŒä¼˜å…ˆçº§é˜Ÿåˆ—æ’åº"""
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.created_at < other.created_at

class ModelInstance:
    """æ¨¡å‹å®ä¾‹ï¼Œç»‘å®šåˆ°ç‰¹å®šGPU"""
    def __init__(self, model: BaseModel, device: str, instance_id: str, physical_gpu_id: str):
        self.model = model
        self.device = device
        self.instance_id = instance_id
        self.physical_gpu_id = physical_gpu_id  # ç‰©ç†GPU ID
        self.is_busy = False
        self.last_used = time.time()
        self.total_generations = 0
        self.current_task = None
        self.lock = threading.Lock()
        self.task_queue = PriorityQueue()  # ä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—
        
        # ä»é…ç½®è·å–é˜Ÿåˆ—å¤§å°é™åˆ¶
        config = Config.get_config()
        self.max_queue_size = config["concurrent"]["max_gpu_queue_size"]
    
    def is_available(self) -> bool:
        """æ£€æŸ¥å®ä¾‹æ˜¯å¦å¯ç”¨"""
        with self.lock:
            return not self.is_busy and self.model.is_loaded
    
    def can_accept_task(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¥å—æ–°ä»»åŠ¡ï¼ˆè€ƒè™‘é˜Ÿåˆ—å¤§å°ï¼‰"""
        return self.task_queue.qsize() < self.max_queue_size
    
    def set_busy(self, busy: bool, task_id: Optional[str] = None):
        """è®¾ç½®å¿™ç¢ŒçŠ¶æ€"""
        with self.lock:
            self.is_busy = busy
            self.current_task = task_id if busy else None
            if not busy:
                self.last_used = time.time()
                self.total_generations += 1
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å®ä¾‹çŠ¶æ€"""
        with self.lock:
            return {
                "instance_id": self.instance_id,
                "device": self.device,
                "physical_gpu_id": self.physical_gpu_id,
                "is_busy": self.is_busy,
                "is_loaded": self.model.is_loaded,
                "current_task": self.current_task,
                "queue_size": self.task_queue.qsize(),
                "max_queue_size": self.max_queue_size,
                "total_generations": self.total_generations,
                "last_used": self.last_used
            }

class ConcurrentModelManager:
    """æ”¹è¿›çš„å¹¶å‘æ¨¡å‹ç®¡ç†å™¨ - æ”¯æŒGPUç¯å¢ƒéš”ç¦»"""
    
    def __init__(self):
        self.device_manager = DeviceManager()
        self.model_instances: Dict[str, List[ModelInstance]] = {}  # model_id -> [instances]
        self.instance_lookup: Dict[str, ModelInstance] = {}  # instance_id -> instance
        
        # å…¨å±€ä»»åŠ¡é˜Ÿåˆ—å’Œè°ƒåº¦
        self.global_task_queue = PriorityQueue()
        self.task_results: Dict[str, Queue] = {}  # task_id -> result_queue
        
        # å·¥ä½œçº¿ç¨‹ç®¡ç†
        self.worker_threads = []
        self.scheduler_thread = None
        self.is_running = False
        
        # ä»é…ç½®è·å–å‚æ•°
        config = Config.get_config()
        self.max_global_queue_size = config["concurrent"]["max_global_queue_size"]
        self.task_timeout = config["concurrent"]["task_timeout"]
        self.scheduler_sleep_time = config["concurrent"]["scheduler_sleep_time"]
        self.load_balance_strategy = config["concurrent"]["load_balance_strategy"]
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "queue_full_rejections": 0
        }
        
        self._initialize_models()
        self._start_manager()
    
    def _create_model_instance_for_gpu(self, model_id: str, gpu_device: str, instance_id: str) -> Optional[ModelInstance]:
        """ä¸ºç‰¹å®šGPUåˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆä½¿ç”¨å­è¿›ç¨‹éš”ç¦»ï¼‰"""
        try:
            # æå–ç‰©ç†GPU ID
            physical_gpu_id = gpu_device.split(":")[1] if gpu_device.startswith("cuda:") else "cpu"
            
            logger.info(f"æ­£åœ¨ä¸ºGPU {physical_gpu_id} åˆ›å»ºæ¨¡å‹å®ä¾‹ {instance_id}")
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            if model_id == "flux1-dev":
                # åˆ›å»ºæ¨¡å‹æ—¶ä¼ å…¥ç‰©ç†GPU IDï¼Œè®©æ¨¡å‹å†…éƒ¨å¤„ç†GPUéš”ç¦»
                model = FluxModel(gpu_device=gpu_device, physical_gpu_id=physical_gpu_id)
            else:
                logger.warning(f"æœªçŸ¥æ¨¡å‹ç±»å‹: {model_id}")
                return None
            
            # åŠ è½½æ¨¡å‹
            if model.load():
                instance = ModelInstance(model, gpu_device, instance_id, physical_gpu_id)
                logger.info(f"âœ… æ¨¡å‹å®ä¾‹ {instance_id} åˆ›å»ºæˆåŠŸï¼Œç‰©ç†GPU: {physical_gpu_id}")
                return instance
            else:
                logger.error(f"âŒ æ¨¡å‹å®ä¾‹ {instance_id} åŠ è½½å¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ¨¡å‹å®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹å®ä¾‹"""
        model_gpu_config = Config.get_config()["model_management"]["model_gpu_config"]
        
        for model_id, gpu_list in model_gpu_config.items():
            if model_id not in self.model_instances:
                self.model_instances[model_id] = []
            
            # ä¸ºæ¯ä¸ªGPUåˆ›å»ºä¸€ä¸ªæ¨¡å‹å®ä¾‹
            for gpu_device in gpu_list:
                if self.device_manager.validate_device(gpu_device):
                    try:
                        # ç”Ÿæˆå”¯ä¸€å®ä¾‹ID
                        instance_id = f"{model_id}_{gpu_device.replace(':', '_')}"
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¿™ä¸ªå®ä¾‹
                        if instance_id in self.instance_lookup:
                            logger.warning(f"å®ä¾‹ {instance_id} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                            continue
                        
                        # åˆ›å»ºæ¨¡å‹å®ä¾‹
                        instance = self._create_model_instance_for_gpu(model_id, gpu_device, instance_id)
                        
                        if instance:
                            self.model_instances[model_id].append(instance)
                            self.instance_lookup[instance_id] = instance
                        else:
                            logger.error(f"âŒ æ— æ³•åˆ›å»ºæ¨¡å‹å®ä¾‹ {instance_id}")
                    except Exception as e:
                        logger.error(f"âŒ åˆ›å»ºæ¨¡å‹å®ä¾‹å¤±è´¥: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
        
        # æ‰“å°åˆå§‹åŒ–ç»“æœ
        total_instances = sum(len(instances) for instances in self.model_instances.values())
        logger.info(f"ğŸ‰ æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œæ€»å…±åˆ›å»ºäº† {total_instances} ä¸ªå®ä¾‹")
        for model_id, instances in self.model_instances.items():
            logger.info(f"  {model_id}: {len(instances)} ä¸ªå®ä¾‹")
            for inst in instances:
                logger.info(f"    - {inst.instance_id} (è®¾å¤‡: {inst.device}, ç‰©ç†GPU: {inst.physical_gpu_id})")
    
    def _start_manager(self):
        """å¯åŠ¨ç®¡ç†å™¨"""
        self.is_running = True
        
        # å¯åŠ¨å…¨å±€è°ƒåº¦å™¨
        self.scheduler_thread = threading.Thread(
            target=self._global_scheduler_loop, 
            name="global-scheduler"
        )
        self.scheduler_thread.daemon = True
        self.scheduler_thread.start()
        logger.info("å…¨å±€è°ƒåº¦å™¨å·²å¯åŠ¨")
        
        # ä¸ºæ¯ä¸ªGPUå®ä¾‹å¯åŠ¨å·¥ä½œçº¿ç¨‹
        for model_id, instances in self.model_instances.items():
            for instance in instances:
                worker = threading.Thread(
                    target=self._gpu_worker_loop,
                    args=(instance,),
                    name=f"worker-{instance.instance_id}"
                )
                worker.daemon = True
                worker.start()
                self.worker_threads.append(worker)
                logger.info(f"GPUå·¥ä½œçº¿ç¨‹ {worker.name} å·²å¯åŠ¨")
    
    def _global_scheduler_loop(self):
        """å…¨å±€è°ƒåº¦å™¨å¾ªç¯ - æ™ºèƒ½ä»»åŠ¡åˆ†é…"""
        logger.info("å…¨å±€è°ƒåº¦å™¨å¼€å§‹è¿è¡Œ")
        
        while self.is_running:
            try:
                # è·å–å…¨å±€ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                task = self.global_task_queue.get(timeout=self.scheduler_sleep_time)
                
                # æ‰¾åˆ°æœ€ä½³çš„GPUå®ä¾‹
                best_instance = self._find_best_instance(task.model_id)
                
                if best_instance:
                    # åˆ†é…ä»»åŠ¡ç»™GPU
                    best_instance.task_queue.put(task)
                    logger.info(f"ä»»åŠ¡ {task.task_id} å·²åˆ†é…ç»™ {best_instance.instance_id} (è®¾å¤‡: {best_instance.device})")
                else:
                    # æ‰€æœ‰GPUéƒ½å¿™ç¢Œæˆ–é˜Ÿåˆ—å·²æ»¡ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—
                    self.global_task_queue.put(task)
                    # æ›´é•¿çš„ç­‰å¾…æ—¶é—´ï¼Œé¿å…CPUå ç”¨è¿‡é«˜
                    time.sleep(self.scheduler_sleep_time * 5)
                    
            except Empty:
                continue
            except Exception as e:
                logger.error(f"å…¨å±€è°ƒåº¦å™¨é”™è¯¯: {e}")
    
    def _find_best_instance(self, model_id: str) -> Optional[ModelInstance]:
        """æ‰¾åˆ°æœ€ä½³çš„æ¨¡å‹å®ä¾‹"""
        if model_id not in self.model_instances:
            logger.warning(f"âš ï¸ æ¨¡å‹ {model_id} ä¸å­˜åœ¨")
            return None
        
        instances = self.model_instances[model_id]
        
        # é¦–å…ˆæ‰¾ç©ºé—²çš„å®ä¾‹
        available_instances = [
            inst for inst in instances 
            if inst.model.is_loaded and not inst.is_busy and inst.can_accept_task()
        ]
        
        if available_instances:
            # é€‰æ‹©é˜Ÿåˆ—æœ€çŸ­çš„ç©ºé—²å®ä¾‹
            best = min(available_instances, key=lambda x: x.task_queue.qsize())
            logger.debug(f"âœ… é€‰æ‹©ç©ºé—²å®ä¾‹ {best.instance_id}ï¼Œé˜Ÿåˆ—å¤§å°: {best.task_queue.qsize()}")
            return best
        
        # å¦‚æœæ²¡æœ‰ç©ºé—²çš„ï¼Œæ‰¾é˜Ÿåˆ—æœªæ»¡çš„å®ä¾‹
        queueable_instances = [
            inst for inst in instances 
            if inst.model.is_loaded and inst.can_accept_task()
        ]
        
        if queueable_instances:
            # é€‰æ‹©é˜Ÿåˆ—æœ€çŸ­çš„å®ä¾‹
            best = min(queueable_instances, key=lambda x: x.task_queue.qsize())
            logger.debug(f"âœ… é€‰æ‹©å¯æ’é˜Ÿå®ä¾‹ {best.instance_id}ï¼Œé˜Ÿåˆ—å¤§å°: {best.task_queue.qsize()}")
            return best
        
        logger.debug(f"âš ï¸ æ¨¡å‹ {model_id} æ²¡æœ‰å¯ç”¨å®ä¾‹")
        return None
    
    def _gpu_worker_loop(self, instance: ModelInstance):
        """GPUå·¥ä½œçº¿ç¨‹å¾ªç¯"""
        logger.info(f"GPUå·¥ä½œçº¿ç¨‹å¼€å§‹è¿è¡Œ: {instance.instance_id}")
        
        while self.is_running:
            try:
                # è·å–ä»»åŠ¡
                task = instance.task_queue.get(timeout=1.0)
                
                # æ ‡è®°ä¸ºå¿™ç¢Œ
                instance.set_busy(True, task.task_id)
                
                # å¤„ç†ä»»åŠ¡
                self._process_task_on_gpu(task, instance)
                
                # æ ‡è®°ä¸ºç©ºé—²
                instance.set_busy(False)
                
            except Empty:
                continue
            except Exception as e:
                logger.error(f"GPUå·¥ä½œçº¿ç¨‹ {instance.instance_id} é”™è¯¯: {e}")
                instance.set_busy(False)
    
    def _process_task_on_gpu(self, task: GenerationTask, instance: ModelInstance):
        """åœ¨GPUä¸Šå¤„ç†ä»»åŠ¡ - çº¿ç¨‹çº§GPUéš”ç¦»ç‰ˆæœ¬"""
        logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {task.task_id[:8]} (å®ä¾‹: {instance.instance_id})")
        
        try:
            # æ›´æ–°æ¨¡å‹è®¾å¤‡é…ç½®
            if hasattr(instance.model, '_update_device_for_task'):
                instance.model._update_device_for_task(instance.device)
            
            # æ‰§è¡Œç”Ÿæˆä»»åŠ¡ - æ¨¡å‹å†…éƒ¨ä¼šä½¿ç”¨torch.cuda.set_device()è¿›è¡Œçº¿ç¨‹çº§éš”ç¦»
            result = instance.model.generate(task.prompt, **task.params)
            
            # æ·»åŠ ä»»åŠ¡ä¿¡æ¯
            result.update({
                "task_id": task.task_id,
                "device": instance.device,
                "instance_id": instance.instance_id,
                "physical_gpu": instance.physical_gpu_id,
                "thread_name": threading.current_thread().name
            })
            
            # å‘é€ç»“æœ
            task.result_queue.put(result)
            
            # æ›´æ–°ç»Ÿè®¡
            if result.get("success", False):
                self.stats["completed_tasks"] += 1
                instance.total_generations += 1
                logger.info(f"âœ… ä»»åŠ¡ {task.task_id[:8]} å®Œæˆ (å®ä¾‹: {instance.instance_id})")
            else:
                self.stats["failed_tasks"] += 1
                logger.error(f"âŒ ä»»åŠ¡ {task.task_id[:8]} å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä»»åŠ¡ {task.task_id[:8]} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # å¤±è´¥æ—¶æ‰§è¡Œå¼ºåˆ¶æ¸…ç†
            try:
                if instance.device.startswith("cuda:"):
                    logger.warning(f"ä»»åŠ¡å¤±è´¥ï¼Œå¯¹GPU {instance.device} æ‰§è¡Œå¼ºåˆ¶æ¸…ç†")
                    self._check_and_cleanup_memory(instance, force_cleanup=True)
            except Exception as cleanup_error:
                logger.error(f"å¼ºåˆ¶æ¸…ç†GPUæ˜¾å­˜æ—¶å‡ºé”™: {cleanup_error}")
            
            result = {
                "success": False,
                "error": str(e),
                "task_id": task.task_id,
                "device": instance.device,
                "instance_id": instance.instance_id,
                "physical_gpu": instance.physical_gpu_id,
                "thread_name": threading.current_thread().name
            }
            task.result_queue.put(result)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["failed_tasks"] += 1
            
        finally:
            # é‡Šæ”¾GPU
            instance.set_busy(False)
    
    async def generate_image_async(self, model_id: str, prompt: str, priority: int = 0, **kwargs) -> Dict[str, Any]:
        """å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡ - æ”¯æŒä¼˜å…ˆçº§"""
        task_id = str(uuid.uuid4())
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨å®ä¾‹
        if model_id not in self.model_instances or not self.model_instances[model_id]:
            return {
                "success": False,
                "error": f"æ¨¡å‹ {model_id} ä¸å¯ç”¨",
                "task_id": task_id
            }
        
        # æ£€æŸ¥å…¨å±€é˜Ÿåˆ—æ˜¯å¦è¿‡è½½
        if self.global_task_queue.qsize() >= self.max_global_queue_size:
            self.stats["queue_full_rejections"] += 1
            return {
                "success": False,
                "error": "æœåŠ¡å™¨è¿‡è½½ï¼Œè¯·ç¨åé‡è¯•",
                "task_id": task_id
            }
        
        # åˆ›å»ºç»“æœé˜Ÿåˆ—
        result_queue = Queue()
        self.task_results[task_id] = result_queue
        
        # åˆ›å»ºä»»åŠ¡
        task = GenerationTask(
            task_id=task_id,
            model_id=model_id,
            prompt=prompt,
            params=kwargs,
            result_queue=result_queue,
            created_at=time.time(),
            priority=priority
        )
        
        # æ·»åŠ åˆ°å…¨å±€ä»»åŠ¡é˜Ÿåˆ—
        self.global_task_queue.put(task)
        self.stats["total_tasks"] += 1
        
        logger.info(f"ä»»åŠ¡ {task_id} å·²åŠ å…¥é˜Ÿåˆ—ï¼Œä¼˜å…ˆçº§: {priority}")
        
        try:
            # ç­‰å¾…ç»“æœï¼ˆä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼‰
            result = await asyncio.get_event_loop().run_in_executor(
                None, result_queue.get, True, self.task_timeout
            )
            return result
            
        except Exception as e:
            logger.error(f"ç­‰å¾…ä»»åŠ¡ {task_id} ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"ä»»åŠ¡è¶…æ—¶æˆ–å‘ç”Ÿé”™è¯¯: {str(e)}",
                "task_id": task_id
            }
        finally:
            # æ¸…ç†ç»“æœé˜Ÿåˆ—
            self.task_results.pop(task_id, None)
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çŠ¶æ€"""
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_queue_size = sum(
            inst.task_queue.qsize() 
            for instances in self.model_instances.values() 
            for inst in instances
        )
        
        busy_instances = sum(
            1 for instances in self.model_instances.values() 
            for inst in instances if inst.is_busy
        )
        
        total_instances = sum(
            len(instances) for instances in self.model_instances.values()
        )
        
        return {
            "is_running": self.is_running,
            "global_queue_size": self.global_task_queue.qsize(),
            "max_global_queue_size": self.max_global_queue_size,
            "total_queue_size": total_queue_size,
            "worker_threads": len(self.worker_threads),
            "busy_instances": busy_instances,
            "total_instances": total_instances,
            "load_balance_strategy": self.load_balance_strategy,
            "task_timeout": self.task_timeout,
            "stats": self.stats.copy(),
            "model_instances": {
                model_id: [inst.get_status() for inst in instances]
                for model_id, instances in self.model_instances.items()
            }
        }
    
    def get_model_list(self) -> List[Dict[str, Any]]:
        """è·å–æ¨¡å‹åˆ—è¡¨"""
        models = []
        for model_id, instances in self.model_instances.items():
            if instances:
                first_instance = instances[0]
                model_info = first_instance.model.get_info()
                model_info.update({
                    "total_instances": len(instances),
                    "available_instances": len([inst for inst in instances if inst.is_available()]),
                    "busy_instances": len([inst for inst in instances if inst.is_busy]),
                    "total_queue_size": sum(inst.task_queue.qsize() for inst in instances)
                })
                models.append(model_info)
        return models
    
    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        logger.info("æ­£åœ¨å…³é—­å¹¶å‘æ¨¡å‹ç®¡ç†å™¨...")
        
        self.is_running = False
        
        # ç­‰å¾…è°ƒåº¦å™¨çº¿ç¨‹ç»“æŸ
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5.0)
        
        # ç­‰å¾…å·¥ä½œçº¿ç¨‹ç»“æŸ
        for worker in self.worker_threads:
            worker.join(timeout=5.0)
        
        # å¸è½½æ‰€æœ‰æ¨¡å‹
        for instances in self.model_instances.values():
            for instance in instances:
                try:
                    logger.info(f"å¸è½½æ¨¡å‹å®ä¾‹: {instance.instance_id}")
                    instance.model.unload()
                except Exception as e:
                    logger.error(f"å¸è½½å®ä¾‹ {instance.instance_id} æ—¶å‡ºé”™: {e}")
        
        logger.info("å¹¶å‘æ¨¡å‹ç®¡ç†å™¨å·²å…³é—­")