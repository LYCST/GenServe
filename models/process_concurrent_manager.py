import asyncio
import threading
import time
import os
import multiprocessing as mp
from typing import Dict, List, Optional, Any, Tuple
import logging
from queue import Queue, Empty, PriorityQueue
import queue
from dataclasses import dataclass, field
import uuid
import torch
from gpu_isolation_manager import GPUIsolationManager
from config import Config
from utils import ValidationUtils, TaskUtils

logger = logging.getLogger(__name__)

@dataclass
class GenerationTask:
    """ç”Ÿæˆä»»åŠ¡"""
    task_id: str
    model_id: str
    prompt: str
    params: Dict[str, Any]
    result_queue: Queue
    created_at: float
    priority: int = 0  # ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    
    def __lt__(self, other):
        """æ”¯æŒä¼˜å…ˆçº§é˜Ÿåˆ—æ’åº"""
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.created_at < other.created_at

class ProcessConcurrentModelManager:
    """è¿›ç¨‹çº§å¹¶å‘æ¨¡å‹ç®¡ç†å™¨ - ä½¿ç”¨å­è¿›ç¨‹å®ç°çœŸæ­£çš„GPUéš”ç¦»"""
    
    def __init__(self):
        self.gpu_manager = GPUIsolationManager()
        self.model_instances: Dict[str, List[str]] = {}  # model_id -> [gpu_ids]
        
        # å…¨å±€ä»»åŠ¡é˜Ÿåˆ—å’Œè°ƒåº¦
        self.global_task_queue = PriorityQueue()
        self.task_results: Dict[str, Queue] = {}  # task_id -> result_queue
        
        # å·¥ä½œçº¿ç¨‹ç®¡ç†
        self.scheduler_thread = None
        self.is_running = False
        
        # è´Ÿè½½å‡è¡¡è®¡æ•°å™¨
        self.gpu_round_robin_counters: Dict[str, int] = {}  # model_id -> counter
        
        # ä»é…ç½®è·å–å‚æ•°
        config = Config.get_config()
        self.max_global_queue_size = config["concurrent"]["max_global_queue_size"]
        self.task_timeout = config["concurrent"]["task_timeout"]
        self.scheduler_sleep_time = config["concurrent"]["scheduler_sleep_time"]
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "queue_full_rejections": 0
        }
        
        self._initialize_models()
        self._start_manager()
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹è¿›ç¨‹"""
        model_gpu_config = Config.get_config()["model_management"]["model_gpu_config"]
        model_paths = Config.get_config()["model_management"]["model_paths"]
        
        for model_id, gpu_list in model_gpu_config.items():
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦é…ç½®
            model_path = model_paths.get(model_id)
            if not model_path:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_id} æœªé…ç½®è·¯å¾„ï¼Œè·³è¿‡")
                continue
            
            if not os.path.exists(model_path):
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_id} è·¯å¾„ä¸å­˜åœ¨: {model_path}ï¼Œè·³è¿‡")
                continue
            
            if model_id not in self.model_instances:
                self.model_instances[model_id] = []
            
            # ä¸ºæ¯ä¸ªGPUåˆ›å»ºéš”ç¦»è¿›ç¨‹
            for gpu_device in gpu_list:
                if gpu_device.startswith("cuda:"):
                    gpu_id = gpu_device.split(":")[1]
                    
                    # åˆ›å»ºGPUéš”ç¦»è¿›ç¨‹
                    if self.gpu_manager.create_gpu_process(gpu_id, model_path, model_id):
                        self.model_instances[model_id].append(gpu_id)
                        logger.info(f"âœ… GPU {gpu_id} è¿›ç¨‹åˆ›å»ºæˆåŠŸ (æ¨¡å‹: {model_id})")
                    else:
                        logger.error(f"âŒ GPU {gpu_id} è¿›ç¨‹åˆ›å»ºå¤±è´¥ (æ¨¡å‹: {model_id})")
        
        # æ‰“å°åˆå§‹åŒ–ç»“æœ
        total_processes = sum(len(gpus) for gpus in self.model_instances.values())
        supported_models = list(self.model_instances.keys())
        
        logger.info(f"ğŸ‰ æ¨¡å‹è¿›ç¨‹åˆå§‹åŒ–å®Œæˆï¼Œæ€»å…±åˆ›å»ºäº† {total_processes} ä¸ªGPUè¿›ç¨‹")
        logger.info(f"ğŸ“‹ æ”¯æŒçš„æ¨¡å‹: {supported_models}")
        
        for model_id, gpus in self.model_instances.items():
            logger.info(f"  {model_id}: {len(gpus)} ä¸ªGPUè¿›ç¨‹ ({gpus})")
    
    def _start_manager(self):
        """å¯åŠ¨ç®¡ç†å™¨"""
        self.is_running = True
        
        # å¯åŠ¨å…¨å±€è°ƒåº¦å™¨
        self.scheduler_thread = threading.Thread(
            target=self._global_scheduler_loop, 
            name="process-scheduler"
        )
        self.scheduler_thread.daemon = True
        self.scheduler_thread.start()
        logger.info("è¿›ç¨‹çº§å…¨å±€è°ƒåº¦å™¨å·²å¯åŠ¨")
        
        # å¯åŠ¨è¿›ç¨‹ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(
            target=self._process_monitor_loop,
            name="process-monitor"
        )
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        logger.info("è¿›ç¨‹ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")
        
        # å¯åŠ¨ç»“æœç›‘å¬å™¨
        self.result_listener_thread = threading.Thread(
            target=self._result_listener_loop,
            name="result-listener"
        )
        self.result_listener_thread.daemon = True
        self.result_listener_thread.start()
        logger.info("ç»“æœç›‘å¬å™¨å·²å¯åŠ¨")
    
    def _process_monitor_loop(self):
        """è¿›ç¨‹ç›‘æ§å¾ªç¯ - å®šæœŸæ£€æŸ¥æ­»äº¡è¿›ç¨‹å¹¶é‡å¯"""
        logger.info("è¿›ç¨‹ç›‘æ§çº¿ç¨‹å¼€å§‹è¿è¡Œ")
        
        while self.is_running:
            try:
                # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡è¿›ç¨‹çŠ¶æ€
                time.sleep(30)
                
                # æ£€æŸ¥å¹¶é‡å¯æ­»äº¡è¿›ç¨‹
                restart_results = self.gpu_manager.check_and_restart_dead_processes()
                
                if restart_results:
                    logger.info(f"è¿›ç¨‹ç›‘æ§: æ£€æŸ¥äº† {len(restart_results)} ä¸ªè¿›ç¨‹")
                    for process_key, success in restart_results.items():
                        if success:
                            logger.info(f"âœ… è¿›ç¨‹ {process_key} é‡å¯æˆåŠŸ")
                        else:
                            logger.warning(f"âš ï¸ è¿›ç¨‹ {process_key} é‡å¯å¤±è´¥")
                
            except Exception as e:
                logger.error(f"è¿›ç¨‹ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
    
    def _result_listener_loop(self):
        """ç»“æœç›‘å¬å™¨å¾ªç¯ - é«˜æ•ˆç›‘å¬æ‰€æœ‰GPUè¿›ç¨‹çš„ç»“æœé˜Ÿåˆ—"""
        logger.info("ğŸ“¡ ç»“æœç›‘å¬å™¨å¼€å§‹è¿è¡Œ")
        
        while self.is_running:
            try:
                # æ£€æŸ¥æ‰€æœ‰GPUè¿›ç¨‹çš„ç»“æœé˜Ÿåˆ—
                for process_key, result_queue in self.gpu_manager.result_queues.items():
                    try:
                        # éé˜»å¡æ–¹å¼æ£€æŸ¥ç»“æœ
                        result = result_queue.get_nowait()
                        
                        if result and 'task_id' in result:
                            task_id = result['task_id']
                            logger.info(f"ğŸ“¨ ç»“æœç›‘å¬å™¨æ”¶åˆ°ä»»åŠ¡ {task_id[:8]} çš„ç»“æœ (GPU: {result.get('gpu_id', 'unknown')})")
                            
                            # æŸ¥æ‰¾å¯¹åº”çš„ä»»åŠ¡ç»“æœé˜Ÿåˆ—
                            if task_id in self.task_results:
                                task_result_queue = self.task_results[task_id]
                                
                                # æ·»åŠ çº¿ç¨‹ä¿¡æ¯
                                result['thread_name'] = threading.current_thread().name
                                
                                # å‘é€ç»“æœ
                                task_result_queue.put(result)
                                logger.info(f"ğŸ“¤ ä»»åŠ¡ {task_id[:8]} ç»“æœå·²å‘é€åˆ°ç»“æœé˜Ÿåˆ—")
                                
                                # æ›´æ–°ç»Ÿè®¡
                                if result.get("success", False):
                                    self.stats["completed_tasks"] += 1
                                    logger.info(f"âœ… ä»»åŠ¡ {task_id[:8]} å®Œæˆ (GPU: {result.get('gpu_id', 'unknown')})")
                                else:
                                    self.stats["failed_tasks"] += 1
                                    logger.error(f"âŒ ä»»åŠ¡ {task_id[:8]} å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                
                                # æ¸…ç†ä»»åŠ¡è®°å½•
                                del self.task_results[task_id]
                                logger.debug(f"ğŸ§¹ ä»»åŠ¡ {task_id[:8]} è®°å½•å·²æ¸…ç† (å‰©ä½™ä»»åŠ¡æ•°: {len(self.task_results)})")
                            else:
                                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡ {task_id[:8]} çš„ç»“æœé˜Ÿåˆ—")
                        
                    except queue.Empty:
                        # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ª
                        continue
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†GPU {process_key} ç»“æœæ—¶å‡ºé”™: {e}")
                
                # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…CPUå ç”¨è¿‡é«˜ï¼Œä½†ä¿æŒå“åº”æ€§
                time.sleep(0.05)  # 50msï¼Œæ¯”åŸæ¥çš„100msæ›´å¿«
                
            except Exception as e:
                logger.error(f"âŒ ç»“æœç›‘å¬å™¨å¾ªç¯é”™è¯¯: {e}")
                import traceback
                logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                time.sleep(1.0)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
    
    def _global_scheduler_loop(self):
        """å…¨å±€è°ƒåº¦å™¨å¾ªç¯ - æ™ºèƒ½ä»»åŠ¡åˆ†é…ï¼Œé«˜å¹¶å‘å¤„ç†"""
        logger.info("ğŸš€ è¿›ç¨‹çº§å…¨å±€è°ƒåº¦å™¨å¼€å§‹è¿è¡Œ")
        
        while self.is_running:
            try:
                # è·å–å…¨å±€ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼Œé¿å…æ— é™é˜»å¡ï¼‰
                try:
                    task = self.global_task_queue.get(timeout=self.scheduler_sleep_time)
                except Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­å¾ªç¯
                    continue
                
                logger.info(f"ğŸ¯ è°ƒåº¦å™¨è·å–åˆ°ä»»åŠ¡: {task.task_id[:8]}, æ¨¡å‹: {task.model_id}, ä¼˜å…ˆçº§: {task.priority}")
                
                # æ‰¾åˆ°æœ€ä½³çš„GPUè¿›ç¨‹
                best_gpu_id = self._find_best_gpu(task.model_id)
                
                if best_gpu_id:
                    # ç«‹å³åˆ†é…ä»»åŠ¡ç»™GPUè¿›ç¨‹ï¼Œä¸ç­‰å¾…å®Œæˆ
                    logger.info(f"ğŸš€ è°ƒåº¦å™¨åˆ†é…ä»»åŠ¡ {task.task_id[:8]} åˆ°GPU {best_gpu_id}")
                    self._submit_task_immediately(task, best_gpu_id)
                    logger.info(f"âœ… ä»»åŠ¡ {task.task_id[:8]} å·²åˆ†é…ç»™GPU {best_gpu_id}")
                else:
                    # æ‰€æœ‰GPUéƒ½å¿™ç¢Œï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§ä¿æŒä¸å˜ï¼‰
                    logger.warning(f"âš ï¸ æ‰€æœ‰GPUéƒ½å¿™ç¢Œï¼Œä»»åŠ¡ {task.task_id[:8]} é‡æ–°æ”¾å›é˜Ÿåˆ—")
                    self.global_task_queue.put(task)
                    # çŸ­æš‚ç­‰å¾…ï¼Œé¿å…CPUå ç”¨è¿‡é«˜
                    time.sleep(self.scheduler_sleep_time * 2)
                    
            except Exception as e:
                logger.error(f"âŒ å…¨å±€è°ƒåº¦å™¨é”™è¯¯: {e}")
                import traceback
                logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                # å‡ºé”™æ—¶çŸ­æš‚ç­‰å¾…ï¼Œé¿å…æ— é™å¾ªç¯
                time.sleep(1.0)
    
    def _find_best_gpu(self, model_id: str) -> Optional[str]:
        """æ‰¾åˆ°æœ€ä½³çš„GPUè¿›ç¨‹ - å®ç°è½®è¯¢è´Ÿè½½å‡è¡¡ï¼Œæ£€æŸ¥å¯ç”¨æ€§"""
        if model_id not in self.model_instances:
            logger.warning(f"âš ï¸ æ¨¡å‹ {model_id} ä¸å­˜åœ¨")
            return None
        
        available_gpus = self.model_instances[model_id]
        
        if not available_gpus:
            logger.debug(f"âš ï¸ æ¨¡å‹ {model_id} æ²¡æœ‰å¯ç”¨GPU")
            return None
        
        # åˆå§‹åŒ–è½®è¯¢è®¡æ•°å™¨
        if model_id not in self.gpu_round_robin_counters:
            self.gpu_round_robin_counters[model_id] = 0
        
        logger.info(f"ğŸ” ä¸ºæ¨¡å‹ {model_id} å¯»æ‰¾å¯ç”¨GPUï¼Œå¯ç”¨GPUåˆ—è¡¨: {available_gpus}")
        
        # å°è¯•æ‰¾åˆ°å¯ç”¨çš„GPUï¼Œæœ€å¤šæ£€æŸ¥æ‰€æœ‰GPUä¸€æ¬¡
        checked_count = 0
        while checked_count < len(available_gpus):
            # è½®è¯¢ç­–ç•¥ï¼šä¾æ¬¡é€‰æ‹©ä¸‹ä¸€ä¸ªGPU
            gpu_index = self.gpu_round_robin_counters[model_id] % len(available_gpus)
            selected_gpu = available_gpus[gpu_index]
            
            logger.info(f"ğŸ² è½®è¯¢é€‰æ‹©GPU {selected_gpu} (ç´¢å¼•: {gpu_index}/{len(available_gpus)})")
            
            # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
            if self._is_gpu_available(selected_gpu, model_id):
                # æ›´æ–°è®¡æ•°å™¨
                self.gpu_round_robin_counters[model_id] += 1
                logger.info(f"âœ… è´Ÿè½½å‡è¡¡: æ¨¡å‹ {model_id} é€‰æ‹©GPU {selected_gpu} (ç´¢å¼•: {gpu_index}/{len(available_gpus)})")
                return selected_gpu
            else:
                # GPUä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                self.gpu_round_robin_counters[model_id] += 1
                checked_count += 1
                logger.info(f"âŒ GPU {selected_gpu} ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª (å·²æ£€æŸ¥: {checked_count}/{len(available_gpus)})")
        
        # æ‰€æœ‰GPUéƒ½ä¸å¯ç”¨
        logger.warning(f"âš ï¸ æ¨¡å‹ {model_id} çš„æ‰€æœ‰GPUéƒ½ä¸å¯ç”¨")
        return None
    
    def _is_gpu_available(self, gpu_id: str, model_id: str) -> bool:
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨ - é«˜æ•ˆæ£€æŸ¥"""
        try:
            process_key = f"{model_id}_{gpu_id}"
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
            if process_key not in self.gpu_manager.processes:
                logger.debug(f"âŒ GPU {gpu_id} è¿›ç¨‹ä¸å­˜åœ¨ (key: {process_key})")
                return False
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æ´»ç€
            process = self.gpu_manager.processes[process_key]
            if not process.is_alive():
                logger.debug(f"âŒ GPU {gpu_id} è¿›ç¨‹å·²æ­»äº¡ (PID: {process.pid}, exitcode: {process.exitcode})")
                return False
            
            # æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
            if process_key in self.gpu_manager.task_queues:
                task_queue = self.gpu_manager.task_queues[process_key]
                try:
                    # éé˜»å¡æ–¹å¼è·å–é˜Ÿåˆ—å¤§å°
                    queue_size = task_queue.qsize()
                    max_queue_size = 5  # æ¯ä¸ªGPUé˜Ÿåˆ—æœ€å¤§å¤§å°
                    
                    if queue_size >= max_queue_size:
                        logger.debug(f"âŒ GPU {gpu_id} ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ (å¤§å°: {queue_size}/{max_queue_size})")
                        return False
                    else:
                        logger.debug(f"âœ… GPU {gpu_id} å¯ç”¨ (é˜Ÿåˆ—å¤§å°: {queue_size}/{max_queue_size})")
                        return True
                        
                except Exception as e:
                    # å¦‚æœæ— æ³•è·å–é˜Ÿåˆ—å¤§å°ï¼Œå‡è®¾å¯ç”¨
                    logger.debug(f"âœ… GPU {gpu_id} å¯ç”¨ (æ— æ³•è·å–é˜Ÿåˆ—å¤§å°: {e})")
                    return True
            else:
                logger.debug(f"âŒ GPU {gpu_id} ä»»åŠ¡é˜Ÿåˆ—ä¸å­˜åœ¨")
                return False
            
        except Exception as e:
            logger.debug(f"âŒ æ£€æŸ¥GPU {gpu_id} å¯ç”¨æ€§æ—¶å‡ºé”™: {e}")
            return False
    
    def _submit_task_immediately(self, task: GenerationTask, gpu_id: str):
        """å¼‚æ­¥æäº¤ä»»åŠ¡åˆ°GPUè¿›ç¨‹ï¼Œä¸é˜»å¡è°ƒåº¦å™¨"""
        logger.info(f"ğŸ“¤ å¼€å§‹æäº¤ä»»åŠ¡ {task.task_id[:8]} åˆ°GPU {gpu_id}")
        
        # å­˜å‚¨ä»»åŠ¡ç»“æœé˜Ÿåˆ—ï¼Œä¾›ç»“æœç›‘å¬å™¨ä½¿ç”¨
        self.task_results[task.task_id] = task.result_queue
        logger.info(f"ğŸ’¾ ä»»åŠ¡ {task.task_id[:8]} ç»“æœé˜Ÿåˆ—å·²å­˜å‚¨ (å½“å‰ä»»åŠ¡æ•°: {len(self.task_results)})")
        
        # åˆ›å»ºåå°çº¿ç¨‹å¤„ç†ä»»åŠ¡ï¼Œä¸é˜»å¡è°ƒåº¦å™¨
        thread = threading.Thread(
            target=self._process_task_on_gpu_process,
            args=(task, gpu_id),
            name=f"task-{task.task_id[:8]}"
        )
        thread.daemon = True
        thread.start()
        logger.info(f"ğŸ§µ ä»»åŠ¡ {task.task_id[:8]} åå°çº¿ç¨‹å·²å¯åŠ¨ (çº¿ç¨‹å: {thread.name})")
        logger.info(f"âœ… ä»»åŠ¡ {task.task_id[:8]} å·²å¼‚æ­¥æäº¤åˆ°GPU {gpu_id}")
    
    def _process_task_on_gpu_process(self, task: GenerationTask, gpu_id: str):
        """åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†GPUä»»åŠ¡ - çœŸæ­£çš„å¼‚æ­¥å¤„ç†"""
        logger.info(f"âš™ï¸ åå°çº¿ç¨‹å¼€å§‹å¤„ç†ä»»åŠ¡ {task.task_id[:8]} (GPU: {gpu_id}, çº¿ç¨‹: {threading.current_thread().name})")
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„ä»»åŠ¡æ•°æ®æ„å»ºå·¥å…·
            task_data = TaskUtils.build_task_data(
                task_id=task.task_id,
                prompt=task.prompt,
                params=task.params
            )
            logger.info(f"ğŸ“‹ ä»»åŠ¡ {task.task_id[:8]} æ•°æ®å·²æ„å»ºï¼Œå‡†å¤‡æäº¤åˆ°GPUè¿›ç¨‹")
            
            # æäº¤ä»»åŠ¡åˆ°GPUè¿›ç¨‹ï¼Œä¸ç­‰å¾…ç»“æœ
            submit_success = self.gpu_manager.submit_task(gpu_id, task.model_id, task_data)
            
            if submit_success:
                logger.info(f"ğŸ¯ ä»»åŠ¡ {task.task_id[:8]} å·²æˆåŠŸæäº¤åˆ°GPU {gpu_id} è¿›ç¨‹ï¼Œç­‰å¾…å¼‚æ­¥ç»“æœ")
                # ä¸åœ¨è¿™é‡Œç­‰å¾…ç»“æœï¼Œè®©GPUè¿›ç¨‹å¼‚æ­¥å¤„ç†
                # ç»“æœä¼šé€šè¿‡GPUè¿›ç¨‹çš„ç»“æœé˜Ÿåˆ—è¿”å›
            else:
                # ä»»åŠ¡æäº¤å¤±è´¥ï¼Œç«‹å³è¿”å›é”™è¯¯
                logger.error(f"âŒ ä»»åŠ¡ {task.task_id[:8]} æäº¤åˆ°GPU {gpu_id} å¤±è´¥")
                error_result = {
                    "success": False,
                    "error": "GPUè¿›ç¨‹ä¸å¯ç”¨æˆ–é˜Ÿåˆ—å·²æ»¡",
                    "task_id": task.task_id,
                    "gpu_id": gpu_id,
                    "model_id": task.model_id
                }
                task.result_queue.put(error_result)
                self.stats["failed_tasks"] += 1
                logger.error(f"âŒ ä»»åŠ¡ {task.task_id[:8]} æäº¤å¤±è´¥")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä»»åŠ¡ {task.task_id[:8]} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            error_result = {
                "success": False,
                "error": str(e),
                "task_id": task.task_id,
                "gpu_id": gpu_id,
                "model_id": task.model_id
            }
            task.result_queue.put(error_result)
            self.stats["failed_tasks"] += 1
        
        logger.info(f"ğŸ åå°çº¿ç¨‹å®Œæˆå¤„ç†ä»»åŠ¡ {task.task_id[:8]} (GPU: {gpu_id})")
    
    async def generate_image_async(
        self, 
        model_id: str, 
        prompt: str, 
        priority: int = 0,
        height: int = 1024,
        width: int = 1024,
        num_inference_steps: int = 50,
        cfg: float = 3.5,
        seed: int = 42,
        mode: str = "text2img",
        strength: float = 0.8,
        input_image: Optional[str] = None,
        mask_image: Optional[str] = None,
        control_image: Optional[str] = None,
        controlnet_type: str = "depth",
        controlnet_conditioning_scale: Optional[float] = None,
        control_guidance_start: Optional[float] = None,
        control_guidance_end: Optional[float] = None,
        loras: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡ - çœŸæ­£çš„å¼‚æ­¥å¹¶è¡Œå¤„ç†"""
        if not self.is_running:
            return {
                "success": False,
                "error": "å¹¶å‘ç®¡ç†å™¨æœªè¿è¡Œ",
                "task_id": "",
                "gpu_id": None,
                "model_id": model_id
            }
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ
        if model_id not in self.model_instances:
            return {
                "success": False,
                "error": f"æ¨¡å‹ {model_id} æœªåŠ è½½",
                "task_id": "",
                "gpu_id": None,
                "model_id": model_id
            }
        
        # éªŒè¯ControlNetç±»å‹
        if mode == "controlnet" and not ValidationUtils.validate_controlnet_type(controlnet_type):
            return {
                "success": False,
                "error": f"ä¸æ”¯æŒçš„controlnetç±»å‹: {controlnet_type}ï¼Œæ”¯æŒçš„ç±»å‹: {ValidationUtils.get_supported_controlnet_types()}",
                "task_id": "",
                "gpu_id": None,
                "model_id": model_id
            }
        
        # åˆ›å»ºä»»åŠ¡
        task_id = str(uuid.uuid4())
        result_queue = Queue()
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ä»»åŠ¡å‚æ•°æ„å»ºå·¥å…·
        task_params = TaskUtils.build_task_params(
            height=height,
            width=width,
            num_inference_steps=num_inference_steps,
            cfg=cfg,
            seed=seed,
            mode=mode,
            strength=strength,
            input_image=input_image,
            mask_image=mask_image,
            control_image=control_image,
            controlnet_type=controlnet_type,
            controlnet_conditioning_scale=controlnet_conditioning_scale,
            control_guidance_start=control_guidance_start,
            control_guidance_end=control_guidance_end,
            loras=loras
        )
        
        task = GenerationTask(
            task_id=task_id,
            model_id=model_id,
            prompt=prompt,
            params=task_params,
            result_queue=result_queue,
            created_at=time.time(),
            priority=priority
        )
        
        logger.info(f"ğŸ”„ åˆ›å»ºä»»åŠ¡: {task_id[:8]}, æ¨¡å‹: {model_id}, æ¨¡å¼: {mode}, ä¼˜å…ˆçº§: {priority}")
        logger.info(f"ğŸ“ ä»»åŠ¡è¯¦æƒ…: æç¤ºè¯='{prompt[:50]}{'...' if len(prompt) > 50 else ''}', å‚æ•°={task_params}")
        
        # æ£€æŸ¥å…¨å±€é˜Ÿåˆ—æ˜¯å¦è¿‡è½½
        if self.global_task_queue.qsize() >= self.max_global_queue_size:
            self.stats["queue_full_rejections"] += 1
            return {
                "success": False,
                "error": "æœåŠ¡å™¨è¿‡è½½ï¼Œè¯·ç¨åé‡è¯•",
                "task_id": task_id,
                "gpu_id": None,
                "model_id": model_id
            }
        
        # æäº¤åˆ°å…¨å±€é˜Ÿåˆ—
        try:
            self.global_task_queue.put(task)
            self.stats["total_tasks"] += 1
            logger.info(f"ğŸ“¥ ä»»åŠ¡ {task_id[:8]} å·²æäº¤åˆ°å…¨å±€é˜Ÿåˆ— (é˜Ÿåˆ—å¤§å°: {self.global_task_queue.qsize()})")
        except Exception as e:
            logger.error(f"âŒ æäº¤ä»»åŠ¡ {task_id[:8]} åˆ°å…¨å±€é˜Ÿåˆ—å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æäº¤ä»»åŠ¡å¤±è´¥: {str(e)}",
                "task_id": task_id,
                "gpu_id": None,
                "model_id": model_id
            }
        
        # å¼‚æ­¥ç­‰å¾…ç»“æœ - ä½¿ç”¨asyncio.get_event_loop().run_in_executor
        try:
            # å°†åŒæ­¥çš„é˜Ÿåˆ—ç­‰å¾…è½¬æ¢ä¸ºå¼‚æ­¥æ“ä½œ
            result = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: result_queue.get(timeout=self.task_timeout)
            )
            
            logger.info(f"âœ… ä»»åŠ¡ {task_id[:8]} å®Œæˆ: {result.get('success', False)}")
            
            # æ·»åŠ ä»»åŠ¡IDåˆ°ç»“æœ
            result["task_id"] = task_id
            result["model_id"] = model_id
            result["mode"] = mode
            if mode == "controlnet":
                result["controlnet_type"] = controlnet_type
            
            return result
            
        except Empty:
            logger.error(f"âŒ ä»»åŠ¡ {task_id[:8]} è¶…æ—¶")
            return {
                "success": False,
                "error": f"ä»»åŠ¡è¶…æ—¶ ({self.task_timeout}ç§’)",
                "task_id": task_id,
                "gpu_id": None,
                "model_id": model_id
            }
        except Exception as e:
            logger.error(f"âŒ ç­‰å¾…ä»»åŠ¡ {task_id[:8]} ç»“æœæ—¶å‡ºé”™: {e}")
            return {
                "success": False,
                "error": f"ç­‰å¾…ç»“æœå¤±è´¥: {str(e)}",
                "task_id": task_id,
                "gpu_id": None,
                "model_id": model_id
            }
        finally:
            # æ¸…ç†ä»»åŠ¡ç»“æœé˜Ÿåˆ—
            self.task_results.pop(task_id, None)
    
    def get_task_result(self, task_id: str, timeout: float = 300) -> Optional[Dict[str, Any]]:
        """æ ¹æ®task_idè·å–ä»»åŠ¡ç»“æœ"""
        if task_id not in self.task_results:
            return {
                "success": False,
                "error": f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨",
                "task_id": task_id
            }
        
        result_queue = self.task_results[task_id]
        
        try:
            result = result_queue.get(timeout=timeout)
            # æ¸…ç†ç»“æœé˜Ÿåˆ—
            del self.task_results[task_id]
            return result
        except Empty:
            return {
                "success": False,
                "error": f"ä»»åŠ¡ {task_id} è¶…æ—¶ ({timeout}ç§’)",
                "task_id": task_id
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"è·å–ä»»åŠ¡ {task_id} ç»“æœå¤±è´¥: {str(e)}",
                "task_id": task_id
            }
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çŠ¶æ€"""
        # è·å–GPUè¿›ç¨‹çŠ¶æ€
        gpu_status = self.gpu_manager.get_gpu_status()
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_processes = sum(len(gpus) for gpus in self.model_instances.values())
        alive_processes = sum(1 for status in gpu_status.values() if status["alive"])
        dead_processes = total_processes - alive_processes
        
        # ç»Ÿè®¡é‡å¯ä¿¡æ¯
        total_restarts = sum(status.get("restart_attempts", 0) for status in gpu_status.values())
        max_restarts_reached = sum(1 for status in gpu_status.values() 
                                 if status.get("restart_attempts", 0) >= status.get("max_restart_attempts", 3))
        
        return {
            "is_running": self.is_running,
            "global_queue_size": self.global_task_queue.qsize(),
            "max_global_queue_size": self.max_global_queue_size,
            "total_processes": total_processes,
            "alive_processes": alive_processes,
            "dead_processes": dead_processes,
            "total_restarts": total_restarts,
            "max_restarts_reached": max_restarts_reached,
            "task_timeout": self.task_timeout,
            "stats": self.stats.copy(),
            "model_instances": {
                model_id: {
                    "gpu_count": len(gpus),
                    "gpu_ids": gpus
                }
                for model_id, gpus in self.model_instances.items()
            },
            "gpu_processes": gpu_status
        }
    
    def get_model_list(self) -> List[Dict[str, Any]]:
        """è·å–æ¨¡å‹åˆ—è¡¨"""
        models = []
        for model_id, gpus in self.model_instances.items():
            model_info = {
                "model_id": model_id,
                "model_name": "FLUX.1-dev" if model_id == "flux1-dev" else model_id,
                "description": "Black Forest Labs FLUX.1-dev model for high-quality image generation",
                "total_gpu_processes": len(gpus),
                "available_gpu_processes": len(gpus),  # ç®€åŒ–ï¼Œå®é™…åº”è¯¥æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                "supported_features": ["text-to-image"]
            }
            models.append(model_info)
        return models
    
    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        logger.info("æ­£åœ¨å…³é—­è¿›ç¨‹çº§å¹¶å‘æ¨¡å‹ç®¡ç†å™¨...")
        
        self.is_running = False
        
        # ç­‰å¾…è°ƒåº¦å™¨çº¿ç¨‹ç»“æŸ
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5.0)
        
        # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
        if hasattr(self, 'monitor_thread') and self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        
        # ç­‰å¾…ç»“æœç›‘å¬å™¨çº¿ç¨‹ç»“æŸ
        if hasattr(self, 'result_listener_thread') and self.result_listener_thread:
            self.result_listener_thread.join(timeout=5.0)
        
        # å…³é—­GPUéš”ç¦»ç®¡ç†å™¨
        self.gpu_manager.shutdown()
        
        logger.info("è¿›ç¨‹çº§å¹¶å‘æ¨¡å‹ç®¡ç†å™¨å·²å…³é—­") 