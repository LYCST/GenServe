import multiprocessing as mp
mp.set_start_method('spawn', force=True)
import asyncio
import logging
import signal
import sys
from fastapi import FastAPI, HTTPException, File, UploadFile, Form
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Dict, Any, Optional, List
import uvicorn
from contextlib import asynccontextmanager
import base64
import io
import json

# å¯¼å…¥è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨
from models.process_concurrent_manager import ProcessConcurrentModelManager
from config import Config
from utils import ValidationUtils, ResponseUtils, GenerateResponse, TaskUtils

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
concurrent_manager: Optional[ProcessConcurrentModelManager] = None

# è¯·æ±‚æ¨¡å‹ - ç”¨äºJSONè¯·æ±‚
class GenerateRequest(BaseModel):
    prompt: str
    model_id: str = "flux1-dev"
    height: int = 1024
    width: int = 1024
    num_inference_steps: int = 50
    cfg: float = 3.5
    seed: int = 42
    priority: int = 0
    mode: str = "text2img"  # text2img, img2img, fill, controlnet, redux
    strength: float = 0.8  # ç”¨äºimg2imgæ¨¡å¼
    input_image: Optional[str] = None  # base64ç¼–ç çš„è¾“å…¥å›¾ç‰‡
    mask_image: Optional[str] = None  # base64ç¼–ç çš„è’™ç‰ˆå›¾ç‰‡ï¼ˆç”¨äºfillæ¨¡å¼ï¼‰
    control_image: Optional[str] = None  # base64ç¼–ç çš„æ§åˆ¶å›¾ç‰‡ï¼ˆç”¨äºcontrolnetæ¨¡å¼ï¼‰
    controlnet_type: str = "depth"  # controlnetç±»å‹ï¼šdepth, canny, openpose
    controlnet_conditioning_scale: Optional[float] = None  # ControlNetæ¡ä»¶å¼ºåº¦ï¼Œæ§åˆ¶æ·±åº¦å›¾å½±å“ç¨‹åº¦
    control_guidance_start: Optional[float] = None  # ControlNetå¼€å§‹ä½œç”¨ç‚¹ï¼ˆ0-1ï¼‰ï¼Œæ§åˆ¶ä½•æ—¶å¼€å§‹åº”ç”¨æ·±åº¦å›¾
    control_guidance_end: Optional[float] = None  # ControlNetç»“æŸä½œç”¨ç‚¹ï¼ˆ0-1ï¼‰ï¼Œæ§åˆ¶ä½•æ—¶åœæ­¢åº”ç”¨æ·±åº¦å›¾
    loras: Optional[List[Dict[str, Any]]] = None  # LoRAé…ç½®åˆ—è¡¨

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global concurrent_manager
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    logger.info("ğŸš€ å¯åŠ¨GenServeæœåŠ¡...")
    
    try:
        # åˆå§‹åŒ–è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨
        concurrent_manager = ProcessConcurrentModelManager()
        logger.info("âœ… è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰“å°é…ç½®æ‘˜è¦
        Config.print_config_summary()
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise
    finally:
        # å…³é—­æ—¶æ¸…ç†
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­GenServeæœåŠ¡...")
        if concurrent_manager:
            concurrent_manager.shutdown()
        logger.info("âœ… æœåŠ¡å·²å…³é—­")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="GenServe - å¤šGPUå›¾ç‰‡ç”ŸæˆæœåŠ¡",
    description="åŸºäºFluxæ¨¡å‹çš„å¤šGPUå¹¶å‘å›¾ç‰‡ç”ŸæˆæœåŠ¡ï¼Œæ”¯æŒJSON(base64)å’ŒForm-data(æ–‡ä»¶ä¸Šä¼ )ä¸¤ç§å›¾ç‰‡ä¸Šä¼ æ–¹å¼",
    version="2.0.0",
    lifespan=lifespan
)

# ä¿¡å·å¤„ç†
def signal_handler(signum, frame):
    """å¤„ç†é€€å‡ºä¿¡å·"""
    logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
    if concurrent_manager:
        concurrent_manager.shutdown()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

async def file_to_base64(file: UploadFile) -> str:
    """å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸ºbase64"""
    try:
        content = await file.read()
        base64_content = base64.b64encode(content).decode()
        return base64_content
    except Exception as e:
        logger.error(f"æ–‡ä»¶è½¬base64å¤±è´¥: {e}")
        logger.error(f"æ–‡ä»¶ä¿¡æ¯: filename={file.filename}, content_type={file.content_type}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "GenServe - å¤šGPUå›¾ç‰‡ç”ŸæˆæœåŠ¡",
        "version": "2.0.0",
        "status": "running",
        "endpoints": {
            "json_base64": "POST /generate",
            "form_data": "POST /generate/upload"
        }
    }

@app.post("/generate", response_model=GenerateResponse)
async def generate_image(request: GenerateRequest):
    """ç”Ÿæˆå›¾ç‰‡ - JSONæ ¼å¼ï¼Œæ”¯æŒbase64ç¼–ç çš„å›¾ç‰‡"""
    if not concurrent_manager:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ª")
    
    try:
        logger.info(f"æ”¶åˆ°è¯·æ±‚: {request.model_id}")
        # è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        supported_models_data = concurrent_manager.get_model_list()
        supported_model_ids = [model['model_id'] for model in supported_models_data]
        
        # ä½¿ç”¨ç»Ÿä¸€çš„éªŒè¯å·¥å…·
        ValidationUtils.validate_generation_request(
            model_id=request.model_id,
            prompt=request.prompt,
            height=request.height,
            width=request.width,
            mode=request.mode,
            controlnet_type=request.controlnet_type,
            input_image=request.input_image,
            mask_image=request.mask_image,
            control_image=request.control_image,
            loras=request.loras,
            supported_models=supported_model_ids
        )
        logger.info(f"æ„å»ºä»»åŠ¡å‚æ•°")
        # æ„å»ºä»»åŠ¡å‚æ•°
        task_params = TaskUtils.build_task_params(
            height=request.height,
            width=request.width,
            num_inference_steps=request.num_inference_steps,
            cfg=request.cfg,
            seed=request.seed,
            mode=request.mode,
            strength=request.strength,
            input_image=request.input_image,
            mask_image=request.mask_image,
            control_image=request.control_image,
            controlnet_type=request.controlnet_type,
            controlnet_conditioning_scale=request.controlnet_conditioning_scale,
            control_guidance_start=request.control_guidance_start,
            control_guidance_end=request.control_guidance_end,
            loras=request.loras
        )
        logger.info(f"è°ƒç”¨è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨")
        # è°ƒç”¨è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨
        result = await concurrent_manager.generate_image_async(
            model_id=request.model_id,
            prompt=request.prompt,
            priority=request.priority,
            **task_params
        )
        logger.info(f"æ„å»ºå“åº”")
        # ä½¿ç”¨ç»Ÿä¸€çš„å“åº”æ„å»ºå·¥å…·
        return ResponseUtils.build_generation_response(
            result=result,
            mode=request.mode,
            controlnet_type=request.controlnet_type
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate/upload", response_model=GenerateResponse)
async def generate_image_upload_general(
    prompt: str = Form(...),
    model_id: str = Form("flux1-dev"),
    height: int = Form(1024),
    width: int = Form(1024),
    num_inference_steps: int = Form(50),
    cfg: float = Form(3.5),
    seed: int = Form(42),
    priority: int = Form(0),
    mode: str = Form("text2img"),  # text2img, img2img, fill, controlnet, redux
    strength: float = Form(0.8),
    input_image: Optional[UploadFile] = File(None),
    mask_image: Optional[UploadFile] = File(None),
    control_image: Optional[UploadFile] = File(None),
    controlnet_type: str = Form("depth"),
    controlnet_conditioning_scale: Optional[float] = Form(None),  # ControlNetæ¡ä»¶å¼ºåº¦
    control_guidance_start: Optional[float] = Form(None),  # ControlNetå¼€å§‹ä½œç”¨ç‚¹
    control_guidance_end: Optional[float] = Form(None),  # ControlNetç»“æŸä½œç”¨ç‚¹
    loras: Optional[str] = Form(None)  # JSONæ ¼å¼çš„LoRAé…ç½®
):
    """ç”Ÿæˆå›¾ç‰‡ - é€šç”¨Form-dataæ ¼å¼ï¼Œæ”¯æŒæ‰€æœ‰æ¨¡å¼çš„æ–‡ä»¶ä¸Šä¼ """
    if not concurrent_manager:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ª")
    
    try:
        # è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        supported_models_data = concurrent_manager.get_model_list()
        supported_model_ids = [model['model_id'] for model in supported_models_data]
        
        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        input_image_base64 = None
        mask_image_base64 = None
        control_image_base64 = None
        
        # æ·»åŠ æ–‡ä»¶ä¸Šä¼ çŠ¶æ€è°ƒè¯•
        
        if input_image:
            logger.info(f"input_imageè¯¦æƒ…: filename={input_image.filename}, content_type={input_image.content_type}")
            input_image_base64 = await file_to_base64(input_image)
            logger.info(f"å¤„ç†input_image: æ–‡ä»¶å¤§å°={input_image.size if hasattr(input_image, 'size') else 'unknown'}")
        
        if mask_image:
            logger.info(f"mask_imageè¯¦æƒ…: filename={mask_image.filename}, content_type={mask_image.content_type}")
            mask_image_base64 = await file_to_base64(mask_image)
            logger.info(f"å¤„ç†mask_image: æ–‡ä»¶å¤§å°={mask_image.size if hasattr(mask_image, 'size') else 'unknown'}")
        
        if control_image:
            logger.info(f"control_imageè¯¦æƒ…: filename={control_image.filename}, content_type={control_image.content_type}")
            control_image_base64 = await file_to_base64(control_image)
            logger.info(f"å¤„ç†control_image: æ–‡ä»¶å¤§å°={control_image.size if hasattr(control_image, 'size') else 'unknown'}")
        
        
        # å¤„ç†LoRAå‚æ•°
        loras_list = None
        if loras:
            try:
                loras_list = json.loads(loras)
                # éªŒè¯LoRAæ ¼å¼
                if not isinstance(loras_list, list):
                    raise ValueError("loraså‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="loraså‚æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            except ValueError as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        # ä½¿ç”¨ç»Ÿä¸€çš„éªŒè¯å·¥å…·
        ValidationUtils.validate_generation_request(
            model_id=model_id,
            prompt=prompt,
            height=height,
            width=width,
            mode=mode,
            controlnet_type=controlnet_type,
            input_image=input_image_base64,
            mask_image=mask_image_base64,
            control_image=control_image_base64,
            loras=loras_list,
            supported_models=supported_model_ids
        )
        
        # æ„å»ºä»»åŠ¡å‚æ•°
        task_params = TaskUtils.build_task_params(
            height=height,
            width=width,
            num_inference_steps=num_inference_steps,
            cfg=cfg,
            seed=seed,
            mode=mode,
            strength=strength,
            input_image=input_image_base64,
            mask_image=mask_image_base64,
            control_image=control_image_base64,
            controlnet_type=controlnet_type,
            controlnet_conditioning_scale=controlnet_conditioning_scale,
            control_guidance_start=control_guidance_start,
            control_guidance_end=control_guidance_end,
            loras=loras_list
        )
        
        # è°ƒç”¨è¿›ç¨‹çº§å¹¶å‘ç®¡ç†å™¨
        result = await concurrent_manager.generate_image_async(
            model_id=model_id,
            prompt=prompt,
            priority=priority,
            **task_params
        )
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å“åº”æ„å»ºå·¥å…·
        return ResponseUtils.build_generation_response(
            result=result,
            mode=mode,
            controlnet_type=controlnet_type
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    if not concurrent_manager:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ª")
    
    status = concurrent_manager.get_status()
    return status

@app.get("/task/{task_id}")
async def get_task_result(task_id: str):
    """æ ¹æ®task_idæŸ¥è¯¢ä»»åŠ¡ç»“æœ"""
    if not concurrent_manager:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ª")
    
    try:
        result = concurrent_manager.get_task_result(task_id)
        if not result:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
        
        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ä»»åŠ¡ {task_id} ç»“æœæ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/models")
async def get_models():
    """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
    if not concurrent_manager:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ª")
    
    return concurrent_manager.get_model_list()

@app.get("/loras")
async def get_loras():
    """è·å–å¯ç”¨çš„LoRAåˆ—è¡¨"""
    try:
        loras = Config.get_lora_list()
        return {
            "success": True,
            "loras": loras,
            "total": len(loras)
        }
    except Exception as e:
        logger.error(f"è·å–LoRAåˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "loras": [],
            "total": 0
        }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    if not concurrent_manager:
        return {"status": "unhealthy", "reason": "concurrent_manager_not_initialized"}
    
    status = concurrent_manager.get_status()
    if status.get("is_running", False):
        return {"status": "healthy"}
    else:
        return {"status": "unhealthy", "reason": "concurrent_manager_not_running"}

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=Config.HOST,
        port=Config.PORT,
        reload=False,
        log_level=Config.LOG_LEVEL.lower()
    ) 