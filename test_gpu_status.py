#!/usr/bin/env python3
"""
GPUè¿›ç¨‹çŠ¶æ€æ£€æŸ¥è„šæœ¬
"""

import requests
import json
import time

def check_service_status():
    """æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
    try:
        response = requests.get("http://localhost:12411/status", timeout=10)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ æœåŠ¡å“åº”é”™è¯¯: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        return None

def test_single_generation():
    """æµ‹è¯•å•ä¸ªå›¾ç‰‡ç”Ÿæˆ"""
    payload = {
        "prompt": "a simple test image",
        "model_id": "flux1-dev",
        "num_inference_steps": 10,  # å‡å°‘æ­¥æ•°åŠ å¿«æµ‹è¯•
        "height": 512,
        "width": 512,
        "seed": 42
    }
    
    try:
        print("ğŸ”„ å‘é€æµ‹è¯•è¯·æ±‚...")
        response = requests.post(
            "http://localhost:12411/generate", 
            json=payload, 
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… è¯·æ±‚æˆåŠŸ: {result.get('success', False)}")
            if result.get('success'):
                print(f"  GPU: {result.get('gpu_id', 'unknown')}")
                print(f"  è€—æ—¶: {result.get('elapsed_time', 0):.2f}ç§’")
                print(f"  ä»»åŠ¡ID: {result.get('task_id', 'unknown')}")
            else:
                print(f"  é”™è¯¯: {result.get('error', 'unknown')}")
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"  å“åº”: {response.text}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¯·æ±‚å¼‚å¸¸: {e}")

def main():
    print("ğŸ” GPUè¿›ç¨‹çŠ¶æ€æ£€æŸ¥")
    print("=" * 50)
    
    # 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
    print("\n1. æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    status = check_service_status()
    if not status:
        print("âŒ æœåŠ¡ä¸å¯ç”¨")
        return
    
    # 2. æ˜¾ç¤ºå¹¶å‘ç®¡ç†å™¨çŠ¶æ€
    concurrent_status = status.get("concurrent_manager", {})
    print(f"ğŸ“Š å¹¶å‘ç®¡ç†å™¨çŠ¶æ€:")
    print(f"  è¿è¡ŒçŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if concurrent_status.get('is_running') else 'ğŸ”´ å·²åœæ­¢'}")
    print(f"  å…¨å±€é˜Ÿåˆ—: {concurrent_status.get('global_queue_size', 0)} ä¸ªä»»åŠ¡")
    print(f"  æ€»è¿›ç¨‹æ•°: {concurrent_status.get('total_processes', 0)}")
    print(f"  æ´»è·ƒè¿›ç¨‹: {concurrent_status.get('alive_processes', 0)}")
    
    # 3. æ˜¾ç¤ºGPUè¿›ç¨‹è¯¦æƒ…
    gpu_processes = concurrent_status.get("gpu_processes", {})
    print(f"\nğŸ¤– GPUè¿›ç¨‹è¯¦æƒ…:")
    for process_key, process_info in gpu_processes.items():
        status_icon = "ğŸŸ¢" if process_info.get("alive") else "ğŸ”´"
        print(f"  {status_icon} {process_key}:")
        print(f"    PID: {process_info.get('pid', 'unknown')}")
        print(f"    çŠ¶æ€: {'æ´»è·ƒ' if process_info.get('alive') else 'æ­»äº¡'}")
        print(f"    é€€å‡ºç : {process_info.get('exitcode', 'unknown')}")
        if not process_info.get("alive"):
            print(f"    âš ï¸ è¿›ç¨‹å·²æ­»äº¡ï¼Œå¯èƒ½éœ€è¦é‡å¯æœåŠ¡")
    
    # 4. æµ‹è¯•å•ä¸ªç”Ÿæˆä»»åŠ¡
    print(f"\n2. æµ‹è¯•å•ä¸ªç”Ÿæˆä»»åŠ¡...")
    test_single_generation()
    
    print(f"\nâœ¨ æ£€æŸ¥å®Œæˆ")

if __name__ == "__main__":
    main() 