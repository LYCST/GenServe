#!/usr/bin/env python3
"""
ç®€å•çš„å¹¶å‘æµ‹è¯•è„šæœ¬ - ä½¿ç”¨curlå‘½ä»¤æµ‹è¯•çœŸæ­£çš„å¹¶å‘
"""

import subprocess
import time
import json
import random
import threading
from concurrent.futures import ThreadPoolExecutor
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def send_single_request(request_id: int, base_url: str = "http://localhost:12411") -> dict:
    """å‘é€å•ä¸ªcurlè¯·æ±‚"""
    try:
        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "prompt": f"Beautiful landscape with mountains and trees, request {request_id}",
            "model_id": "flux1-dev",
            "height": 512,
            "width": 512,
            "num_inference_steps": 10,
            "cfg": 3.5,
            "seed": random.randint(1, 1000000),
            "priority": random.randint(0, 3),
            "mode": "text2img"
        }
        
        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
        json_data = json.dumps(data)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        logger.info(f"ğŸš€ è¯·æ±‚ {request_id}: å¼€å§‹å‘é€curlè¯·æ±‚")
        
        # æ‰§è¡Œcurlå‘½ä»¤
        cmd = [
            "curl", "-X", "POST",
            f"{base_url}/generate",
            "-H", "Content-Type: application/json",
            "-d", json_data,
            "-s"  # é™é»˜æ¨¡å¼
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = time.time() - start_time
        
        if result.returncode == 0:
            try:
                response_json = json.loads(result.stdout)
                success = response_json.get("success", False)
                task_id = response_json.get("task_id", "")
                gpu_id = response_json.get("gpu_id", "")
                
                logger.info(f"âœ… è¯·æ±‚ {request_id}: æˆåŠŸï¼ŒGPU: {gpu_id}, è€—æ—¶: {response_time:.2f}s")
                
                return {
                    "request_id": request_id,
                    "success": success,
                    "response_time": response_time,
                    "task_id": task_id,
                    "gpu_id": gpu_id,
                    "status_code": 200
                }
            except json.JSONDecodeError:
                logger.error(f"âŒ è¯·æ±‚ {request_id}: JSONè§£æå¤±è´¥")
                return {
                    "request_id": request_id,
                    "success": False,
                    "response_time": response_time,
                    "error": "JSONè§£æå¤±è´¥",
                    "status_code": 0
                }
        else:
            logger.error(f"âŒ è¯·æ±‚ {request_id}: curlå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {
                "request_id": request_id,
                "success": False,
                "response_time": response_time,
                "error": f"curlå¤±è´¥: {result.stderr}",
                "status_code": result.returncode
            }
            
    except subprocess.TimeoutExpired:
        logger.error(f"âŒ è¯·æ±‚ {request_id}: è¶…æ—¶")
        return {
            "request_id": request_id,
            "success": False,
            "response_time": 300,
            "error": "è¯·æ±‚è¶…æ—¶",
            "status_code": 0
        }
    except Exception as e:
        logger.error(f"âŒ è¯·æ±‚ {request_id}: å¼‚å¸¸: {e}")
        return {
            "request_id": request_id,
            "success": False,
            "response_time": 0,
            "error": str(e),
            "status_code": 0
        }

def test_concurrent_requests(base_url: str = "http://localhost:12411", total_requests: int = 5):
    """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
    logger.info(f"ğŸ¯ å¼€å§‹å¹¶å‘æµ‹è¯•: {total_requests} ä¸ªè¯·æ±‚")
    logger.info(f"ğŸŒ ç›®æ ‡URL: {base_url}")
    
    # è®°å½•æ€»ä½“å¼€å§‹æ—¶é—´
    overall_start = time.time()
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=total_requests) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_request = {
            executor.submit(send_single_request, i+1, base_url): i+1 
            for i in range(total_requests)
        }
        
        # æ”¶é›†ç»“æœ
        results = []
        for future in future_to_request:
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                request_id = future_to_request[future]
                logger.error(f"âŒ è¯·æ±‚ {request_id} æ‰§è¡Œå¼‚å¸¸: {e}")
                results.append({
                    "request_id": request_id,
                    "success": False,
                    "error": str(e)
                })
    
    # è®¡ç®—æ€»ä½“è€—æ—¶
    overall_time = time.time() - overall_start
    
    # åˆ†æç»“æœ
    analyze_results(results, overall_time)

def analyze_results(results: list, overall_time: float):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    logger.info("=" * 60)
    logger.info("ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœåˆ†æ")
    logger.info("=" * 60)
    
    total_requests = len(results)
    successful_requests = sum(1 for r in results if r.get("success", False))
    failed_requests = total_requests - successful_requests
    
    logger.info(f"æ€»è¯·æ±‚æ•°: {total_requests}")
    logger.info(f"æˆåŠŸè¯·æ±‚: {successful_requests}")
    logger.info(f"å¤±è´¥è¯·æ±‚: {failed_requests}")
    logger.info(f"æ€»è€—æ—¶: {overall_time:.2f}s")
    
    if successful_requests > 0:
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r.get("response_time", 0) for r in results if r.get("success", False)]
        avg_response_time = sum(response_times) / len(response_times)
        max_response_time = max(response_times)
        min_response_time = min(response_times)
        
        logger.info(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
        logger.info(f"æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}s")
        logger.info(f"æœ€å°å“åº”æ—¶é—´: {min_response_time:.2f}s")
        
        # GPUä½¿ç”¨ç»Ÿè®¡
        gpu_usage = {}
        for result in results:
            if result.get("success") and result.get("gpu_id"):
                gpu_id = result["gpu_id"]
                gpu_usage[gpu_id] = gpu_usage.get(gpu_id, 0) + 1
        
        logger.info("\nğŸ® GPUä½¿ç”¨æƒ…å†µ:")
        for gpu_id, count in sorted(gpu_usage.items()):
            logger.info(f"  GPU {gpu_id}: {count} ä¸ªè¯·æ±‚")
        
        # å¹¶å‘åº¦è¯„ä¼°
        if overall_time < max_response_time * 1.5:
            logger.info("âœ… æ€»ä½“è€—æ—¶æ¥è¿‘æœ€å¤§å“åº”æ—¶é—´ï¼Œå¹¶å‘æ•ˆæœè‰¯å¥½")
        else:
            logger.warning("âš ï¸ æ€»ä½“è€—æ—¶è¿œå¤§äºæœ€å¤§å“åº”æ—¶é—´ï¼Œå¯èƒ½å­˜åœ¨ä¸²è¡ŒåŒ–")
    
    logger.info("=" * 60)

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    BASE_URL = "http://localhost:12411"
    TOTAL_REQUESTS = 5  # å‡å°‘è¯·æ±‚æ•°ä»¥ä¾¿è§‚å¯Ÿ
    
    try:
        test_concurrent_requests(BASE_URL, TOTAL_REQUESTS)
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc()) 