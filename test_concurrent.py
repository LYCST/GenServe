#!/usr/bin/env python3
"""
GenServe å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•è„šæœ¬
æµ‹è¯•å¤šGPUå¹¶å‘å¤„ç†èƒ½åŠ›å’Œé˜Ÿåˆ—ç®¡ç†
"""

import asyncio
import time
import json
from datetime import datetime
import base64
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import uuid
import urllib.request
import urllib.parse
import urllib.error
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    request_id: str
    prompt: str
    start_time: float
    end_time: float
    success: bool
    device: str = ""
    worker: str = ""
    task_id: str = ""
    generation_time: float = 0.0
    queue_wait_time: float = 0.0
    error: str = ""

class EnhancedConcurrentTester:
    """å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:12411"):
        self.base_url = base_url
        self.test_results: List[TestResult] = []
        self.session_lock = threading.Lock()
    
    def make_request(self, url: str, method: str = "GET", data: Optional[Dict] = None, timeout: int = 300) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚"""
        try:
            if data:
                data_bytes = json.dumps(data).encode('utf-8')
                req = urllib.request.Request(url, data=data_bytes, method=method)
                req.add_header('Content-Type', 'application/json')
            else:
                req = urllib.request.Request(url, method=method)
            
            with urllib.request.urlopen(req, timeout=timeout) as response:
                response_data = response.read().decode('utf-8')
                return json.loads(response_data)
        except urllib.error.HTTPError as e:
            error_data = e.read().decode('utf-8')
            return {"error": f"HTTP {e.code}: {error_data}"}
        except Exception as e:
            return {"error": str(e)}
    
    def get_service_status(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æœåŠ¡çŠ¶æ€"""
        return self.make_request(f"{self.base_url}/status")
    
    def display_service_info(self):
        """æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯"""
        print("ğŸ” è·å–æœåŠ¡çŠ¶æ€...")
        status = self.get_service_status()
        
        if "error" in status:
            print(f"âŒ æ— æ³•è·å–æœåŠ¡çŠ¶æ€: {status['error']}")
            return False
        
        print("=" * 60)
        print("ğŸš€ GenServe æœåŠ¡çŠ¶æ€")
        print("=" * 60)
        
        # å¹¶å‘ç®¡ç†å™¨çŠ¶æ€
        concurrent_status = status.get("concurrent_manager", {})
        print(f"ğŸ“Š å¹¶å‘ç®¡ç†å™¨:")
        print(f"  è¿è¡ŒçŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if concurrent_status.get('is_running') else 'ğŸ”´ å·²åœæ­¢'}")
        print(f"  å…¨å±€é˜Ÿåˆ—: {concurrent_status.get('global_queue_size', 0)} ä¸ªä»»åŠ¡")
        print(f"  æ€»é˜Ÿåˆ—å¤§å°: {concurrent_status.get('total_queue_size', 0)} ä¸ªä»»åŠ¡")
        print(f"  å·¥ä½œçº¿ç¨‹: {concurrent_status.get('worker_threads', 0)} ä¸ª")
        print(f"  å¿™ç¢Œå®ä¾‹: {concurrent_status.get('busy_instances', 0)}/{concurrent_status.get('total_instances', 0)}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = concurrent_status.get('stats', {})
        print(f"  æ€»ä»»åŠ¡: {stats.get('total_tasks', 0)}")
        print(f"  å·²å®Œæˆ: {stats.get('completed_tasks', 0)}")
        print(f"  å¤±è´¥: {stats.get('failed_tasks', 0)}")
        print(f"  é˜Ÿåˆ—æ»¡æ‹’ç»: {stats.get('queue_full_rejections', 0)}")
        
        # æ¨¡å‹å®ä¾‹è¯¦æƒ…
        model_instances = concurrent_status.get('model_instances', {})
        for model_id, instances in model_instances.items():
            print(f"\nğŸ¤– æ¨¡å‹ {model_id}:")
            if isinstance(instances, list):
                for instance in instances:
                    if isinstance(instance, dict):
                        status_icon = "ğŸ”´" if instance.get('is_busy', False) else "ğŸŸ¢"
                        current_task = f" (ä»»åŠ¡: {instance.get('current_task', 'None')})" if instance.get('is_busy', False) else ""
                        print(f"  {status_icon} {instance.get('device', 'unknown')}: é˜Ÿåˆ—={instance.get('queue_size', 0)}/{instance.get('max_queue_size', 0)}, æ€»ç”Ÿæˆ={instance.get('total_generations', 0)}{current_task}")
                    else:
                        print(f"  âš ï¸ å®ä¾‹æ•°æ®æ ¼å¼é”™è¯¯: {instance}")
            else:
                print(f"  âš ï¸ å®ä¾‹åˆ—è¡¨æ ¼å¼é”™è¯¯: {instances}")
        
        # GPUè´Ÿè½½ä¿¡æ¯
        gpu_load = status.get("gpu_load", {})
        if gpu_load:
            print(f"\nğŸ’¾ GPUå†…å­˜ä½¿ç”¨:")
            for gpu_id, load_info in gpu_load.items():
                if load_info.get('available'):
                    utilization = load_info.get('utilization_percent', 0)
                    free_mb = load_info.get('free_mb', 0)
                    total_mb = load_info.get('total_mb', 0)
                    print(f"  {gpu_id}: {utilization:.1f}% ä½¿ç”¨ä¸­, {free_mb:.0f}MB/{total_mb:.0f}MB å¯ç”¨")
        
        print("=" * 60)
        return True
    
    def generate_single_image(self, prompt: str, request_id: str, priority: int = 0) -> TestResult:
        """ç”Ÿæˆå•å¼ å›¾ç‰‡å¹¶è®°å½•è¯¦ç»†ä¿¡æ¯"""
        payload = {
            "prompt": prompt,
            "model_id": "flux1-dev",  # ä¿®æ­£å­—æ®µå
            "num_inference_steps": 20,
            "height": 512,
            "width": 512,
            "seed": abs(hash(request_id)) % 10000  # åŸºäºrequest_idç”Ÿæˆç¨³å®šçš„ç§å­
        }
        
        result = TestResult(
            request_id=request_id,
            prompt=prompt,
            start_time=time.time(),
            end_time=0,
            success=False
        )
        
        try:
            response_data = self.make_request(
                f"{self.base_url}/generate", 
                method="POST",
                data=payload,
                timeout=300
            )
            
            result.end_time = time.time()
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
            if response_data.get("success", False):
                result.success = True
                result.device = response_data.get("gpu_id", "unknown")  # æ˜ å°„ gpu_id -> device
                result.worker = response_data.get("model_id", "unknown")  # æ˜ å°„ model_id -> worker
                result.task_id = response_data.get("task_id", "")
                
                # è§£æç”Ÿæˆæ—¶é—´ - elapsed_time æ˜¯ float ç±»å‹
                elapsed_time = response_data.get("elapsed_time", 0.0)
                if isinstance(elapsed_time, (int, float)):
                    result.generation_time = float(elapsed_time)
                else:
                    result.generation_time = 0.0
                
                # è®¡ç®—é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
                total_time = result.end_time - result.start_time
                result.queue_wait_time = max(0, total_time - result.generation_time)
                
                # ä¿å­˜å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰- æ˜ å°„ image_base64 -> output
                if response_data.get("image_base64") and os.getenv("SAVE_TEST_IMAGES", "false").lower() == "true":
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    image_path = f"test_{request_id}_{timestamp}.png"
                    
                    image_data = base64.b64decode(response_data["image_base64"])
                    with open(image_path, "wb") as f:
                        f.write(image_data)
            else:
                # å¤„ç†å¤±è´¥æƒ…å†µ
                result.error = response_data.get("error", "æœªçŸ¥é”™è¯¯")
                
        except Exception as e:
            result.end_time = time.time()
            result.error = str(e)
        
        return result
    
    def burst_test(self, prompts: List[str], burst_size: int, max_workers: int = 10) -> List[TestResult]:
        """çªå‘æµ‹è¯• - ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å‘é€å¤šä¸ªè¯·æ±‚"""
        print(f"\nğŸ’¥ çªå‘æµ‹è¯•: å‘é€ {burst_size} ä¸ªè¯·æ±‚ (æœ€å¤§å¹¶å‘: {max_workers})")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_request = {}
            for i in range(burst_size):
                prompt = prompts[i % len(prompts)]
                request_id = f"burst_{i+1}_{uuid.uuid4().hex[:8]}"
                future = executor.submit(self.generate_single_image, prompt, request_id)
                future_to_request[future] = request_id
            
            # æ”¶é›†ç»“æœï¼Œè®¾ç½®è¶…æ—¶
            print(f"â³ ç­‰å¾… {burst_size} ä¸ªè¯·æ±‚å®Œæˆ...")
            timeout_start = time.time()
            timeout_duration = 120.0  # 2åˆ†é’Ÿæ€»ä½“è¶…æ—¶
            
            try:
                for future in as_completed(future_to_request):
                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                    if time.time() - timeout_start > timeout_duration:
                        print(f"âš ï¸ çªå‘æµ‹è¯•è¶…æ—¶ï¼Œè·³è¿‡å‰©ä½™ {len(future_to_request)} ä¸ªä»»åŠ¡")
                        break
                        
                    try:
                        result = future.result(timeout=10.0)  # å•ä¸ªä»»åŠ¡10ç§’è¶…æ—¶
                        print(result)   
                        results.append(result)
                        print(f"âœ… è¯·æ±‚ {future_to_request[future]} å®Œæˆ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                    except Exception as e:
                        print(f"âŒ è¯·æ±‚ {future_to_request[future]} å¼‚å¸¸: {e}")
                        # å³ä½¿å¼‚å¸¸ä¹Ÿè¦è®°å½•å¤±è´¥ç»“æœ
                        failed_result = TestResult(
                            request_id=future_to_request[future],
                            prompt="",
                            start_time=time.time(),
                            end_time=time.time(),
                            success=False,
                            error=str(e)
                        )
                        results.append(failed_result)
                        
            except KeyboardInterrupt:
                print(f"\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
                # è®°å½•å‰©ä½™ä»»åŠ¡ä¸ºå¤±è´¥
                for future in future_to_request:
                    if future not in [r.request_id for r in results]:
                        failed_result = TestResult(
                            request_id=future_to_request[future],
                            prompt="",
                            start_time=time.time(),
                            end_time=time.time(),
                            success=False,
                            error="æµ‹è¯•è¢«ä¸­æ–­"
                        )
                        results.append(failed_result)
        
        print(f"ğŸ“Š çªå‘æµ‹è¯•ç»Ÿè®¡: æäº¤ {burst_size} ä¸ªè¯·æ±‚ï¼Œå®Œæˆ {len(results)} ä¸ªç»“æœ")
        self.test_results.extend(results)
        return results
    
    def sustained_load_test(self, prompts: List[str], duration: int, rate: float, max_workers: int = 10) -> List[TestResult]:
        """æŒç»­è´Ÿè½½æµ‹è¯•"""
        print(f"\nâ±ï¸ æŒç»­è´Ÿè½½æµ‹è¯•: {duration}ç§’, æ¯ç§’{rate}ä¸ªè¯·æ±‚ (æœ€å¤§å¹¶å‘: {max_workers})")
        
        end_time = time.time() + duration
        results = []
        request_count = 0
        submitted_count = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_request = {}
            
            while time.time() < end_time:
                # è®¡ç®—ä¸‹ä¸€æ‰¹è¯·æ±‚æ•°é‡
                interval = 1.0 / rate
                batch_size = max(1, int(rate))
                
                # æäº¤ä¸€æ‰¹è¯·æ±‚
                for i in range(batch_size):
                    if time.time() >= end_time:
                        break
                    
                    prompt = prompts[request_count % len(prompts)]
                    request_id = f"sustained_{submitted_count+1}_{uuid.uuid4().hex[:8]}"
                    future = executor.submit(self.generate_single_image, prompt, request_id)
                    future_to_request[future] = request_id
                    request_count += 1
                    submitted_count += 1
                
                # æ”¶é›†å·²å®Œæˆçš„ç»“æœ
                completed_futures = []
                for future in list(future_to_request.keys()):
                    if future.done():
                        try:
                            # è®¾ç½®è¶…æ—¶ï¼Œé¿å…å¡ä½
                            result = future.result(timeout=10.0)  # 10ç§’è¶…æ—¶
                            print(result)   
                            results.append(result)
                            print(f"âœ… è¯·æ±‚ {future_to_request[future]} å®Œæˆ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                        except Exception as e:
                            print(f"âŒ è¯·æ±‚ {future_to_request[future]} å¼‚å¸¸: {e}")
                        completed_futures.append(future)
                
                # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                for future in completed_futures:
                    del future_to_request[future]
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´
                time.sleep(interval)
            
            # ç­‰å¾…å‰©ä½™ä»»åŠ¡å®Œæˆï¼Œè®¾ç½®æ€»ä½“è¶…æ—¶
            remaining_count = len(future_to_request)
            if remaining_count > 0:
                print(f"â³ ç­‰å¾…å‰©ä½™ {remaining_count} ä¸ªä»»åŠ¡å®Œæˆ...")
                
                # è®¾ç½®æ€»ä½“è¶…æ—¶æ—¶é—´
                timeout_start = time.time()
                timeout_duration = 60.0  # 60ç§’æ€»ä½“è¶…æ—¶
                
                try:
                    for future in as_completed(future_to_request):
                        # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                        if time.time() - timeout_start > timeout_duration:
                            print(f"âš ï¸ ç­‰å¾…å‰©ä½™ä»»åŠ¡è¶…æ—¶ï¼Œè·³è¿‡å‰©ä½™ {len(future_to_request)} ä¸ªä»»åŠ¡")
                            break
                            
                        try:
                            result = future.result(timeout=5.0)  # å•ä¸ªä»»åŠ¡5ç§’è¶…æ—¶
                            print(result)   
                            results.append(result)
                            print(f"âœ… è¯·æ±‚ {future_to_request[future]} å®Œæˆ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                        except Exception as e:
                            print(f"âŒ è¯·æ±‚ {future_to_request[future]} å¼‚å¸¸: {e}")
                            # å³ä½¿å¼‚å¸¸ä¹Ÿè¦è®°å½•å¤±è´¥ç»“æœ
                            failed_result = TestResult(
                                request_id=future_to_request[future],
                                prompt="",
                                start_time=time.time(),
                                end_time=time.time(),
                                success=False,
                                error=str(e)
                            )
                            results.append(failed_result)
                            
                except KeyboardInterrupt:
                    print(f"\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
                    # è®°å½•å‰©ä½™ä»»åŠ¡ä¸ºå¤±è´¥
                    for future in future_to_request:
                        if future not in [r.request_id for r in results]:
                            failed_result = TestResult(
                                request_id=future_to_request[future],
                                prompt="",
                                start_time=time.time(),
                                end_time=time.time(),
                                success=False,
                                error="æµ‹è¯•è¢«ä¸­æ–­"
                            )
                            results.append(failed_result)
        
        print(f"ğŸ“Š æŒç»­è´Ÿè½½æµ‹è¯•ç»Ÿè®¡: æäº¤ {submitted_count} ä¸ªè¯·æ±‚ï¼Œå®Œæˆ {len(results)} ä¸ªç»“æœ")
        self.test_results.extend(results)
        return results
    
    def analyze_results(self, results: List[TestResult], test_name: str = "æµ‹è¯•"):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            print(f"âŒ {test_name}: æ²¡æœ‰ç»“æœæ•°æ®")
            return
        
        print(f"\nğŸ“Š {test_name} ç»“æœåˆ†æ:")
        print("=" * 60)
        
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        print(f"âœ… æˆåŠŸ: {len(successful)}/{len(results)} ({len(successful)/len(results)*100:.1f}%)")
        print(f"âŒ å¤±è´¥: {len(failed)}")
        
        if successful:
            # æ—¶é—´ç»Ÿè®¡
            total_times = [r.end_time - r.start_time for r in successful]
            generation_times = [r.generation_time for r in successful if r.generation_time > 0]
            queue_wait_times = [r.queue_wait_time for r in successful if r.queue_wait_time > 0]
            
            print(f"\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
            print(f"  æ€»æ—¶é—´: å¹³å‡ {sum(total_times)/len(total_times):.2f}s, ä¸­ä½æ•° {sorted(total_times)[len(total_times)//2]:.2f}s")
            if generation_times:
                print(f"  ç”Ÿæˆæ—¶é—´: å¹³å‡ {sum(generation_times)/len(generation_times):.2f}s, ä¸­ä½æ•° {sorted(generation_times)[len(generation_times)//2]:.2f}s")
            if queue_wait_times:
                print(f"  é˜Ÿåˆ—ç­‰å¾…: å¹³å‡ {sum(queue_wait_times)/len(queue_wait_times):.2f}s, ä¸­ä½æ•° {sorted(queue_wait_times)[len(queue_wait_times)//2]:.2f}s")
            
            # è®¾å¤‡åˆ†å¸ƒ
            device_counts = {}
            worker_counts = {}
            for r in successful:
                device_counts[r.device] = device_counts.get(r.device, 0) + 1
                worker_counts[r.worker] = worker_counts.get(r.worker, 0) + 1
            
            print(f"\nğŸ¯ è®¾å¤‡åˆ†å¸ƒ:")
            for device, count in sorted(device_counts.items()):
                print(f"  {device}: {count} æ¬¡ ({count/len(successful)*100:.1f}%)")
            
            print(f"\nğŸ‘· å·¥ä½œçº¿ç¨‹åˆ†å¸ƒ:")
            for worker, count in sorted(worker_counts.items()):
                print(f"  {worker}: {count} æ¬¡ ({count/len(successful)*100:.1f}%)")
        
        if failed:
            print(f"\nâŒ å¤±è´¥åŸå› :")
            error_counts = {}
            for r in failed:
                error_type = r.error.split(':')[0] if ':' in r.error else r.error
                error_counts[error_type] = error_counts.get(error_type, 0) + 1
            
            for error, count in sorted(error_counts.items()):
                print(f"  {error}: {count} æ¬¡")
    
    def create_simple_report(self, results: List[TestResult], save_path: str = "test_report.txt"):
        """åˆ›å»ºç®€å•çš„æ–‡æœ¬æŠ¥å‘Š"""
        if not results:
            return
        
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("GenServe å¹¶å‘æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»è¯·æ±‚æ•°: {len(results)}\n")
            
            successful = [r for r in results if r.success]
            f.write(f"æˆåŠŸè¯·æ±‚: {len(successful)}\n")
            f.write(f"å¤±è´¥è¯·æ±‚: {len(results) - len(successful)}\n")
            f.write(f"æˆåŠŸç‡: {len(successful)/len(results)*100:.1f}%\n\n")
            
            if successful:
                total_times = [r.end_time - r.start_time for r in successful]
                f.write(f"å¹³å‡å“åº”æ—¶é—´: {sum(total_times)/len(total_times):.2f}ç§’\n")
                f.write(f"æœ€å¿«å“åº”æ—¶é—´: {min(total_times):.2f}ç§’\n")
                f.write(f"æœ€æ…¢å“åº”æ—¶é—´: {max(total_times):.2f}ç§’\n\n")
                
                # è®¾å¤‡åˆ†å¸ƒ
                device_counts = {}
                for r in successful:
                    device_counts[r.device] = device_counts.get(r.device, 0) + 1
                
                f.write("è®¾å¤‡è´Ÿè½½åˆ†å¸ƒ:\n")
                for device, count in sorted(device_counts.items()):
                    f.write(f"  {device}: {count} æ¬¡ ({count/len(successful)*100:.1f}%)\n")
        
        print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {save_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ GenServe å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æç¤ºè¯
    test_prompts = [
        "a serene mountain landscape with a crystal clear lake reflecting the sky",
        "a playful golden retriever running through a field of sunflowers",
        "a futuristic cityscape with flying cars and neon lights",
        "a cozy coffee shop interior with warm lighting and wooden furniture",
        "a majestic dragon soaring through stormy clouds"
    ]
    
    tester = EnhancedConcurrentTester()
    
    # 1. æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯
    print("\n1. ğŸ“‹ æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    if not tester.display_service_info():
        print("âŒ æœåŠ¡æœªæ­£å¸¸è¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
        return
    
    # 2. çªå‘æµ‹è¯•
    print("\n2. ğŸ’¥ çªå‘æµ‹è¯•...")
    burst_results = tester.burst_test(test_prompts, 5, max_workers=5)  # 5ä¸ªå¹¶å‘è¯·æ±‚
    tester.analyze_results(burst_results, "çªå‘æµ‹è¯•")
    
    # ç­‰å¾…æœåŠ¡ç¨³å®š
    time.sleep(5)
    
    # 3. æŒç»­è´Ÿè½½æµ‹è¯•
    print("\n3. â±ï¸ æŒç»­è´Ÿè½½æµ‹è¯•...")
    load_results = tester.sustained_load_test(test_prompts, 30, 0.5, max_workers=8)  # 30ç§’ï¼Œæ¯ç§’0.5ä¸ªè¯·æ±‚
    tester.analyze_results(load_results, "æŒç»­è´Ÿè½½æµ‹è¯•")
    
    # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("\n4. ğŸ“Š ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
    all_results = tester.test_results
    tester.analyze_results(all_results, "ç»¼åˆæµ‹è¯•")
    
    # åˆ›å»ºæ–‡æœ¬æŠ¥å‘Š
    tester.create_simple_report(all_results)
    
    # 5. æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    print("\n5. ğŸ” æœ€ç»ˆçŠ¶æ€æ£€æŸ¥...")
    tester.display_service_info()
    
    print(f"\nâœ¨ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ å¦‚æœå¯ç”¨äº†å›¾ç‰‡ä¿å­˜ï¼ˆSAVE_TEST_IMAGES=trueï¼‰ï¼Œå›¾ç‰‡å°†ä¿å­˜åœ¨å½“å‰ç›®å½•")

if __name__ == "__main__":
    main()