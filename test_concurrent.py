#!/usr/bin/env python3
"""
GenServe å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•è„šæœ¬
æµ‹è¯•å¤šGPUå¹¶å‘å¤„ç†èƒ½åŠ›å’Œé˜Ÿåˆ—ç®¡ç†
"""

import asyncio
import aiohttp
import time
import json
from datetime import datetime
import base64
import os
from typing import List, Dict, Any
import matplotlib.pyplot as plt
import numpy as np
from dataclasses import dataclass
import uuid

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    request_id: str
    prompt: str
    start_time: float
    end_time: float
    success: bool
    device: str = ""
    worker: str = ""
    task_id: str = ""
    generation_time: float = 0.0
    queue_wait_time: float = 0.0
    error: str = ""

class EnhancedConcurrentTester:
    """å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:12411"):
        self.base_url = base_url
        self.session = None
        self.test_results: List[TestResult] = []
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def get_service_status(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æœåŠ¡çŠ¶æ€"""
        try:
            async with self.session.get(f"{self.base_url}/status") as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return {"error": f"HTTP {response.status}"}
        except Exception as e:
            return {"error": str(e)}
    
    async def display_service_info(self):
        """æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯"""
        print("ğŸ” è·å–æœåŠ¡çŠ¶æ€...")
        status = await self.get_service_status()
        
        if "error" in status:
            print(f"âŒ æ— æ³•è·å–æœåŠ¡çŠ¶æ€: {status['error']}")
            return False
        
        print("=" * 60)
        print("ğŸš€ GenServe æœåŠ¡çŠ¶æ€")
        print("=" * 60)
        
        # å¹¶å‘ç®¡ç†å™¨çŠ¶æ€
        concurrent_status = status.get("concurrent_manager", {})
        print(f"ğŸ“Š å¹¶å‘ç®¡ç†å™¨:")
        print(f"  è¿è¡ŒçŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if concurrent_status.get('is_running') else 'ğŸ”´ å·²åœæ­¢'}")
        print(f"  å…¨å±€é˜Ÿåˆ—: {concurrent_status.get('global_queue_size', 0)} ä¸ªä»»åŠ¡")
        print(f"  æ€»é˜Ÿåˆ—å¤§å°: {concurrent_status.get('total_queue_size', 0)} ä¸ªä»»åŠ¡")
        print(f"  å·¥ä½œçº¿ç¨‹: {concurrent_status.get('worker_threads', 0)} ä¸ª")
        print(f"  å¿™ç¢Œå®ä¾‹: {concurrent_status.get('busy_instances', 0)}/{concurrent_status.get('total_instances', 0)}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = concurrent_status.get('stats', {})
        print(f"  æ€»ä»»åŠ¡: {stats.get('total_tasks', 0)}")
        print(f"  å·²å®Œæˆ: {stats.get('completed_tasks', 0)}")
        print(f"  å¤±è´¥: {stats.get('failed_tasks', 0)}")
        print(f"  é˜Ÿåˆ—æ»¡æ‹’ç»: {stats.get('queue_full_rejections', 0)}")
        
        # æ¨¡å‹å®ä¾‹è¯¦æƒ…
        model_instances = concurrent_status.get('model_instances', {})
        for model_id, instances in model_instances.items():
            print(f"\nğŸ¤– æ¨¡å‹ {model_id}:")
            for instance in instances:
                status_icon = "ğŸ”´" if instance['is_busy'] else "ğŸŸ¢"
                current_task = f" (ä»»åŠ¡: {instance.get('current_task', 'None')})" if instance['is_busy'] else ""
                print(f"  {status_icon} {instance['device']}: é˜Ÿåˆ—={instance['queue_size']}/{instance['max_queue_size']}, æ€»ç”Ÿæˆ={instance['total_generations']}{current_task}")
        
        # GPUè´Ÿè½½ä¿¡æ¯
        gpu_load = status.get("gpu_load", {})
        if gpu_load:
            print(f"\nğŸ’¾ GPUå†…å­˜ä½¿ç”¨:")
            for gpu_id, load_info in gpu_load.items():
                if load_info.get('available'):
                    utilization = load_info.get('utilization_percent', 0)
                    free_mb = load_info.get('free_mb', 0)
                    total_mb = load_info.get('total_mb', 0)
                    print(f"  {gpu_id}: {utilization:.1f}% ä½¿ç”¨ä¸­, {free_mb:.0f}MB/{total_mb:.0f}MB å¯ç”¨")
        
        print("=" * 60)
        return True
    
    async def generate_single_image(self, prompt: str, request_id: str, priority: int = 0) -> TestResult:
        """ç”Ÿæˆå•å¼ å›¾ç‰‡å¹¶è®°å½•è¯¦ç»†ä¿¡æ¯"""
        payload = {
            "prompt": prompt,
            "model": "flux1-dev",
            "num_inference_steps": 20,
            "height": 512,
            "width": 512,
            "seed": abs(hash(request_id)) % 10000  # åŸºäºrequest_idç”Ÿæˆç¨³å®šçš„ç§å­
        }
        
        result = TestResult(
            request_id=request_id,
            prompt=prompt,
            start_time=time.time(),
            end_time=0,
            success=False
        )
        
        try:
            async with self.session.post(
                f"{self.base_url}/generate", 
                json=payload,
                timeout=aiohttp.ClientTimeout(total=300)
            ) as response:
                
                result.end_time = time.time()
                
                if response.status == 200:
                    data = await response.json()
                    
                    result.success = True
                    result.device = data.get("device", "unknown")
                    result.worker = data.get("worker", "unknown")
                    result.task_id = data.get("task_id", "")
                    
                    # è§£æç”Ÿæˆæ—¶é—´
                    elapsed_str = data.get("elapsed_time", "0s")
                    if elapsed_str.endswith('s'):
                        try:
                            result.generation_time = float(elapsed_str[:-1])
                        except:
                            result.generation_time = 0.0
                    
                    # è®¡ç®—é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
                    total_time = result.end_time - result.start_time
                    result.queue_wait_time = max(0, total_time - result.generation_time)
                    
                    # ä¿å­˜å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
                    if data.get("output") and os.getenv("SAVE_TEST_IMAGES", "false").lower() == "true":
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        image_path = f"test_{request_id}_{timestamp}.png"
                        
                        image_data = base64.b64decode(data["output"])
                        with open(image_path, "wb") as f:
                            f.write(image_data)
                
                else:
                    error_text = await response.text()
                    result.error = f"HTTP {response.status}: {error_text}"
                    
        except asyncio.TimeoutError:
            result.end_time = time.time()
            result.error = "è¯·æ±‚è¶…æ—¶"
        except Exception as e:
            result.end_time = time.time()
            result.error = str(e)
        
        return result
    
    async def burst_test(self, prompts: List[str], burst_size: int, burst_interval: float = 0) -> List[TestResult]:
        """çªå‘æµ‹è¯• - å¿«é€Ÿå‘é€å¤šä¸ªè¯·æ±‚"""
        print(f"\nğŸ’¥ çªå‘æµ‹è¯•: å‘é€ {burst_size} ä¸ªè¯·æ±‚")
        
        tasks = []
        for i in range(burst_size):
            prompt = prompts[i % len(prompts)]
            request_id = f"burst_{i+1}_{uuid.uuid4().hex[:8]}"
            task = self.generate_single_image(prompt, request_id)
            tasks.append(task)
            
            # çªå‘é—´éš”
            if burst_interval > 0 and i < burst_size - 1:
                await asyncio.sleep(burst_interval)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤å¼‚å¸¸
        valid_results = [r for r in results if isinstance(r, TestResult)]
        self.test_results.extend(valid_results)
        
        return valid_results
    
    async def sustained_load_test(self, prompts: List[str], duration: int, rate: float) -> List[TestResult]:
        """æŒç»­è´Ÿè½½æµ‹è¯•"""
        print(f"\nâ±ï¸ æŒç»­è´Ÿè½½æµ‹è¯•: {duration}ç§’, æ¯ç§’{rate}ä¸ªè¯·æ±‚")
        
        end_time = time.time() + duration
        results = []
        request_count = 0
        
        while time.time() < end_time:
            # è®¡ç®—ä¸‹ä¸€æ‰¹è¯·æ±‚æ•°é‡
            interval = 1.0 / rate
            batch_size = max(1, int(rate))
            
            # å‘é€ä¸€æ‰¹è¯·æ±‚
            tasks = []
            for i in range(batch_size):
                if time.time() >= end_time:
                    break
                
                prompt = prompts[request_count % len(prompts)]
                request_id = f"sustained_{request_count+1}_{uuid.uuid4().hex[:8]}"
                task = self.generate_single_image(prompt, request_id)
                tasks.append(task)
                request_count += 1
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´
            if tasks:
                # ä¸ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œç»§ç»­å‘é€
                asyncio.create_task(self._collect_results(tasks, results))
            
            await asyncio.sleep(interval)
        
        # ç­‰å¾…å‰©ä½™ä»»åŠ¡å®Œæˆ
        print(f"â³ ç­‰å¾…å‰©ä½™ä»»åŠ¡å®Œæˆ...")
        await asyncio.sleep(30)  # ç­‰å¾…30ç§’è®©ä»»åŠ¡å®Œæˆ
        
        self.test_results.extend(results)
        return results
    
    async def _collect_results(self, tasks: List, results: List[TestResult]):
        """æ”¶é›†ä»»åŠ¡ç»“æœ"""
        try:
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            for result in task_results:
                if isinstance(result, TestResult):
                    results.append(result)
        except Exception as e:
            print(f"æ”¶é›†ç»“æœæ—¶å‡ºé”™: {e}")
    
    def analyze_results(self, results: List[TestResult], test_name: str = "æµ‹è¯•"):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            print(f"âŒ {test_name}: æ²¡æœ‰ç»“æœæ•°æ®")
            return
        
        print(f"\nğŸ“Š {test_name} ç»“æœåˆ†æ:")
        print("=" * 60)
        
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        print(f"âœ… æˆåŠŸ: {len(successful)}/{len(results)} ({len(successful)/len(results)*100:.1f}%)")
        print(f"âŒ å¤±è´¥: {len(failed)}")
        
        if successful:
            # æ—¶é—´ç»Ÿè®¡
            total_times = [r.end_time - r.start_time for r in successful]
            generation_times = [r.generation_time for r in successful if r.generation_time > 0]
            queue_wait_times = [r.queue_wait_time for r in successful if r.queue_wait_time > 0]
            
            print(f"\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
            print(f"  æ€»æ—¶é—´: å¹³å‡ {np.mean(total_times):.2f}s, ä¸­ä½æ•° {np.median(total_times):.2f}s")
            if generation_times:
                print(f"  ç”Ÿæˆæ—¶é—´: å¹³å‡ {np.mean(generation_times):.2f}s, ä¸­ä½æ•° {np.median(generation_times):.2f}s")
            if queue_wait_times:
                print(f"  é˜Ÿåˆ—ç­‰å¾…: å¹³å‡ {np.mean(queue_wait_times):.2f}s, ä¸­ä½æ•° {np.median(queue_wait_times):.2f}s")
            
            # è®¾å¤‡åˆ†å¸ƒ
            device_counts = {}
            worker_counts = {}
            for r in successful:
                device_counts[r.device] = device_counts.get(r.device, 0) + 1
                worker_counts[r.worker] = worker_counts.get(r.worker, 0) + 1
            
            print(f"\nğŸ¯ è®¾å¤‡åˆ†å¸ƒ:")
            for device, count in sorted(device_counts.items()):
                print(f"  {device}: {count} æ¬¡ ({count/len(successful)*100:.1f}%)")
            
            print(f"\nğŸ‘· å·¥ä½œçº¿ç¨‹åˆ†å¸ƒ:")
            for worker, count in sorted(worker_counts.items()):
                print(f"  {worker}: {count} æ¬¡ ({count/len(successful)*100:.1f}%)")
        
        if failed:
            print(f"\nâŒ å¤±è´¥åŸå› :")
            error_counts = {}
            for r in failed:
                error_type = r.error.split(':')[0] if ':' in r.error else r.error
                error_counts[error_type] = error_counts.get(error_type, 0) + 1
            
            for error, count in sorted(error_counts.items()):
                print(f"  {error}: {count} æ¬¡")
    
    def create_performance_chart(self, results: List[TestResult], save_path: str = "performance_chart.png"):
        """åˆ›å»ºæ€§èƒ½å›¾è¡¨"""
        if not results:
            return
        
        successful = [r for r in results if r.success]
        if not successful:
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('GenServe å¹¶å‘æ€§èƒ½åˆ†æ', fontsize=16)
        
        # 1. æ—¶é—´çº¿å›¾
        start_times = [(r.start_time - successful[0].start_time) for r in successful]
        total_times = [r.end_time - r.start_time for r in successful]
        
        ax1.scatter(start_times, total_times, alpha=0.6)
        ax1.set_xlabel('è¯·æ±‚å¼€å§‹æ—¶é—´ (ç§’)')
        ax1.set_ylabel('æ€»å¤„ç†æ—¶é—´ (ç§’)')
        ax1.set_title('è¯·æ±‚å¤„ç†æ—¶é—´åˆ†å¸ƒ')
        ax1.grid(True)
        
        # 2. è®¾å¤‡è´Ÿè½½åˆ†å¸ƒ
        devices = [r.device for r in successful]
        device_counts = {d: devices.count(d) for d in set(devices)}
        
        ax2.bar(device_counts.keys(), device_counts.values())
        ax2.set_xlabel('è®¾å¤‡')
        ax2.set_ylabel('ä»»åŠ¡æ•°é‡')
        ax2.set_title('è®¾å¤‡è´Ÿè½½åˆ†å¸ƒ')
        ax2.tick_params(axis='x', rotation=45)
        
        # 3. å“åº”æ—¶é—´ç›´æ–¹å›¾
        ax3.hist(total_times, bins=20, alpha=0.7, edgecolor='black')
        ax3.set_xlabel('æ€»å¤„ç†æ—¶é—´ (ç§’)')
        ax3.set_ylabel('é¢‘æ¬¡')
        ax3.set_title('å“åº”æ—¶é—´åˆ†å¸ƒ')
        ax3.grid(True)
        
        # 4. é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
        queue_times = [r.queue_wait_time for r in successful if r.queue_wait_time > 0]
        if queue_times:
            ax4.hist(queue_times, bins=20, alpha=0.7, edgecolor='black', color='orange')
            ax4.set_xlabel('é˜Ÿåˆ—ç­‰å¾…æ—¶é—´ (ç§’)')
            ax4.set_ylabel('é¢‘æ¬¡')
            ax4.set_title('é˜Ÿåˆ—ç­‰å¾…æ—¶é—´åˆ†å¸ƒ')
            ax4.grid(True)
        else:
            ax4.text(0.5, 0.5, 'æ— é˜Ÿåˆ—ç­‰å¾…æ•°æ®', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('é˜Ÿåˆ—ç­‰å¾…æ—¶é—´åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ æ€§èƒ½å›¾è¡¨å·²ä¿å­˜: {save_path}")

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ GenServe å¢å¼ºç‰ˆå¹¶å‘æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æç¤ºè¯
    test_prompts = [
        "a serene mountain landscape with a crystal clear lake reflecting the sky",
        "a playful golden retriever running through a field of sunflowers",
    ]
    
    async with EnhancedConcurrentTester() as tester:
        # 1. æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯
        print("\n1. ğŸ“‹ æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
        if not await tester.display_service_info():
            print("âŒ æœåŠ¡æœªæ­£å¸¸è¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
            return
        
        # 2. çªå‘æµ‹è¯•
        print("\n2. ğŸ’¥ çªå‘æµ‹è¯•...")
        burst_results = await tester.burst_test(test_prompts, 2)  # 6ä¸ªå¹¶å‘è¯·æ±‚
        tester.analyze_results(burst_results, "çªå‘æµ‹è¯•")
        
        # # ç­‰å¾…æœåŠ¡ç¨³å®š
        # await asyncio.sleep(5)
        
        # # 3. æŒç»­è´Ÿè½½æµ‹è¯•
        # print("\n3. â±ï¸ æŒç»­è´Ÿè½½æµ‹è¯•...")
        # load_results = await tester.sustained_load_test(test_prompts, 60, 0.5)  # 60ç§’ï¼Œæ¯ç§’0.5ä¸ªè¯·æ±‚
        # tester.analyze_results(load_results, "æŒç»­è´Ÿè½½æµ‹è¯•")
        
        # # 4. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        # print("\n4. ğŸ“Š ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
        # all_results = tester.test_results
        # tester.analyze_results(all_results, "ç»¼åˆæµ‹è¯•")
        
        # # åˆ›å»ºå›¾è¡¨ï¼ˆå¦‚æœå®‰è£…äº†matplotlibï¼‰
        # try:
        #     tester.create_performance_chart(all_results)
        # except ImportError:
        #     print("ğŸ“ˆ è¦ç”Ÿæˆæ€§èƒ½å›¾è¡¨ï¼Œè¯·å®‰è£…matplotlib: pip install matplotlib")
        # except Exception as e:
        #     print(f"ğŸ“ˆ ç”Ÿæˆå›¾è¡¨æ—¶å‡ºé”™: {e}")
        
        # # 5. æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
        # print("\n5. ğŸ” æœ€ç»ˆçŠ¶æ€æ£€æŸ¥...")
        # await tester.display_service_info()
    
    print(f"\nâœ¨ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ å¦‚æœå¯ç”¨äº†å›¾ç‰‡ä¿å­˜ï¼ˆSAVE_TEST_IMAGES=trueï¼‰ï¼Œå›¾ç‰‡å°†ä¿å­˜åœ¨å½“å‰ç›®å½•")

if __name__ == "__main__":
    asyncio.run(main())