#!/usr/bin/env python3
"""
å¿«é€Ÿå¹¶å‘æµ‹è¯•è„šæœ¬ - éªŒè¯å¹¶å‘æœºåˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import aiohttp
import time
import json
import random
from typing import List, Dict, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_concurrent_requests(base_url: str = "http://localhost:12411", total_requests: int = 10):
    """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
    logger.info(f"å¼€å§‹å¿«é€Ÿå¹¶å‘æµ‹è¯•")
    logger.info(f"   æ€»è¯·æ±‚æ•°: {total_requests}")
    logger.info(f"   æœåŠ¡åœ°å€: {base_url}")
    
    # åˆ›å»ºè¿æ¥å™¨
    connector = aiohttp.TCPConnector(limit=total_requests, limit_per_host=total_requests)
    
    async with aiohttp.ClientSession(connector=connector) as session:
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = []
        start_times = []
        
        for i in range(total_requests):
            start_time = time.time()
            start_times.append(start_time)
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "prompt": f"Beautiful landscape with mountains and trees, request {i+1}",
                "model_id": "flux1-dev",
                "height": 512,
                "width": 512,
                "num_inference_steps": 10,  # å‡å°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
                "cfg": 3.5,
                "seed": random.randint(1, 1000000),
                "priority": random.randint(0, 3),
                "mode": "text2img"
            }
            
            # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
            task = test_single_request(session, i + 1, base_url, data, start_time)
            tasks.append(task)
        
        # åŒæ—¶å‘é€æ‰€æœ‰è¯·æ±‚
        logger.info(f"ğŸ“¤ åŒæ—¶å‘é€ {len(tasks)} ä¸ªè¯·æ±‚...")
        overall_start = time.time()
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        overall_time = time.time() - overall_start
        
        # å¤„ç†ç»“æœ
        valid_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}")
            else:
                valid_results.append(result)
        
        logger.info(f"å¹¶å‘æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {overall_time:.2f}s")
        
        # åˆ†æç»“æœ
        analyze_concurrent_results(valid_results, overall_time, start_times)

async def test_single_request(session: aiohttp.ClientSession, request_id: int, base_url: str, data: Dict, start_time: float) -> Dict[str, Any]:
    """æµ‹è¯•å•ä¸ªè¯·æ±‚ - åŒæ­¥ç­‰å¾…ç»“æœ"""
    try:
        logger.info(f"è¯·æ±‚ {request_id}: å¼€å§‹å‘é€")
        
        async with session.post(f"{base_url}/generate", json=data) as response:
            response_time = time.time() - start_time
            response_text = await response.text()
            
            result = {
                "request_id": request_id,
                "status_code": response.status,
                "response_time": response_time,
                "success": response.status == 200,
                "timestamp": start_time
            }
            
            if response.status == 200:
                try:
                    response_json = await response.json()
                    result["task_id"] = response_json.get("task_id", "")
                    result["gpu_id"] = response_json.get("gpu_id", "")
                    result["model_id"] = response_json.get("model_id", "")
                    logger.info(f"è¯·æ±‚ {request_id}: æˆåŠŸï¼Œç‰©ç†GPU: {result['gpu_id']}, è€—æ—¶: {response_time:.2f}s")
                except:
                    logger.warning(f"è¯·æ±‚ {request_id}: å“åº”è§£æå¤±è´¥")
            else:
                logger.error(f"è¯·æ±‚ {request_id}: âŒ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
            
            return result
            
    except Exception as e:
        response_time = time.time() - start_time
        logger.error(f"è¯·æ±‚ {request_id}: âŒ å¼‚å¸¸: {e}")
        return {
            "request_id": request_id,
            "status_code": 0,
            "response_time": response_time,
            "success": False,
            "error": str(e),
            "timestamp": start_time
        }

def analyze_concurrent_results(results: List[Dict[str, Any]], overall_time: float, start_times: List[float]):
    """åˆ†æå¹¶å‘æµ‹è¯•ç»“æœ"""
    if not results:
        logger.warning("æ²¡æœ‰æµ‹è¯•ç»“æœå¯åˆ†æ")
        return
    
    # åŸºç¡€ç»Ÿè®¡
    total_requests = len(results)
    successful_requests = sum(1 for r in results if r.get("success", False))
    failed_requests = total_requests - successful_requests
    
    # å“åº”æ—¶é—´ç»Ÿè®¡
    response_times = [r.get("response_time", 0) for r in results if r.get("success", False)]
    avg_response_time = sum(response_times) / len(response_times) if response_times else 0
    max_response_time = max(response_times) if response_times else 0
    min_response_time = min(response_times) if response_times else 0
    
    # è®¡ç®—å¹¶å‘åº¦
    first_start = min(start_times)
    last_start = max(start_times)
    request_spread = last_start - first_start
    
    # GPUä½¿ç”¨ç»Ÿè®¡
    gpu_usage = {}
    for result in results:
        if result.get("success") and result.get("gpu_id"):
            gpu_id = result["gpu_id"]
            gpu_usage[gpu_id] = gpu_usage.get(gpu_id, 0) + 1
    
    # æ‰“å°åˆ†æç»“æœ
    logger.info("=" * 60)
    logger.info("ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœåˆ†æ")
    logger.info("=" * 60)
    logger.info(f"æ€»è¯·æ±‚æ•°: {total_requests}")
    logger.info(f"æˆåŠŸè¯·æ±‚: {successful_requests} ({successful_requests/total_requests*100:.1f}%)")
    logger.info(f"å¤±è´¥è¯·æ±‚: {failed_requests} ({failed_requests/total_requests*100:.1f}%)")
    logger.info(f"æ€»è€—æ—¶: {overall_time:.2f}s")
    logger.info(f"è¯·æ±‚å‘é€æ—¶é—´è·¨åº¦: {request_spread:.2f}s")
    logger.info(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
    logger.info(f"æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}s")
    logger.info(f"æœ€å°å“åº”æ—¶é—´: {min_response_time:.2f}s")
    
    # å¹¶å‘åº¦è¯„ä¼°
    if request_spread < 1.0:
        logger.info("âœ… è¯·æ±‚å‘é€æ—¶é—´è·¨åº¦å¾ˆå°ï¼Œå¹¶å‘åº¦è‰¯å¥½")
    else:
        logger.warning("âš ï¸ è¯·æ±‚å‘é€æ—¶é—´è·¨åº¦è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨ä¸²è¡ŒåŒ–é—®é¢˜")
    
    # å“åº”æ—¶é—´åˆ†æ
    if max_response_time - min_response_time < 5.0:
        logger.info("âœ… å“åº”æ—¶é—´å·®å¼‚è¾ƒå°ï¼Œè´Ÿè½½å‡è¡¡è‰¯å¥½")
    else:
        logger.warning("âš ï¸ å“åº”æ—¶é—´å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨è´Ÿè½½ä¸å‡è¡¡")
    
    logger.info("\nç‰©ç†GPUä½¿ç”¨æƒ…å†µ:")
    for gpu_id, count in sorted(gpu_usage.items()):
        logger.info(f"  ç‰©ç†GPU {gpu_id}: {count} ä¸ªè¯·æ±‚")
    
    # æ£€æŸ¥è´Ÿè½½å‡è¡¡
    if len(gpu_usage) > 1:
        gpu_counts = list(gpu_usage.values())
        max_gpu_count = max(gpu_counts)
        min_gpu_count = min(gpu_counts)
        balance_ratio = min_gpu_count / max_gpu_count if max_gpu_count > 0 else 1.0
        logger.info(f"\nâš–ï¸ è´Ÿè½½å‡è¡¡è¯„ä¼°: {balance_ratio:.2f} (1.0ä¸ºå®Œç¾å‡è¡¡)")
        
        if balance_ratio < 0.5:
            logger.warning("âš ï¸ è´Ÿè½½å‡è¡¡æ•ˆæœè¾ƒå·®")
        elif balance_ratio < 0.8:
            logger.info("ğŸ“Š è´Ÿè½½å‡è¡¡æ•ˆæœä¸€èˆ¬")
        else:
            logger.info("âœ… è´Ÿè½½å‡è¡¡æ•ˆæœè‰¯å¥½")
    
    # å¹¶å‘æ€§èƒ½è¯„ä¼°
    if successful_requests == total_requests:
        logger.info("âœ… æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸï¼Œå¹¶å‘å¤„ç†æ­£å¸¸")
    else:
        logger.warning(f"âš ï¸ æœ‰ {failed_requests} ä¸ªè¯·æ±‚å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
    
    if overall_time < max_response_time * 1.5:
        logger.info("âœ… æ€»ä½“è€—æ—¶æ¥è¿‘æœ€å¤§å“åº”æ—¶é—´ï¼Œå¹¶å‘æ•ˆæœè‰¯å¥½")
    else:
        logger.warning("âš ï¸ æ€»ä½“è€—æ—¶è¿œå¤§äºæœ€å¤§å“åº”æ—¶é—´ï¼Œå¯èƒ½å­˜åœ¨ä¸²è¡ŒåŒ–")
    
    logger.info("=" * 60)

async def main():
    """ä¸»å‡½æ•°"""
    # æµ‹è¯•é…ç½®
    BASE_URL = "http://localhost:12411"  # æœåŠ¡åœ°å€
    TOTAL_REQUESTS = 10  # æ€»è¯·æ±‚æ•°
    
    try:
        # è¿è¡Œå¹¶å‘æµ‹è¯•
        await test_concurrent_requests(BASE_URL, TOTAL_REQUESTS)
        
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main()) 