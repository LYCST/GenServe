import os
import subprocess
import multiprocessing as mp
from typing import Dict, Any, Optional, Callable
import logging
import time
import signal
import sys
import traceback
import queue
import gc
import psutil

# mp.set_start_method('spawn', force=True)

logger = logging.getLogger(__name__)

def gpu_worker_process(gpu_id: str, model_path: str, model_id: str, task_queue, result_queue):
    """GPUå·¥ä½œè¿›ç¨‹ - åœ¨éš”ç¦»ç¯å¢ƒä¸­è¿è¡Œï¼ˆé¡¶å±‚å‡½æ•°ï¼Œæ”¯æŒspawnï¼‰"""
    import logging
    import traceback
    import queue
    from models.flux_model import FluxModel
    import time
    import os
    import gc

    logger = logging.getLogger(f"gpu_worker_{gpu_id}")
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
    model = None
    try:
        # åœ¨GPUå·¥ä½œè¿›ç¨‹ä¸­ï¼Œç”±äºè®¾ç½®äº†CUDA_VISIBLE_DEVICESï¼Œåªèƒ½çœ‹åˆ°GPU 0
        # æ‰€ä»¥ä½¿ç”¨cuda:0è€Œä¸æ˜¯cuda:{gpu_id}
        model = FluxModel(model_id=model_id, gpu_device="cuda:0", physical_gpu_id=gpu_id)
        if not model.load():
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_id} on GPU {gpu_id}")
            result_queue.put({"success": False, "error": f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_id}", "gpu_id": gpu_id})
            return
        logger.info(f"æ¨¡å‹ {model_id} å·²åŠ è½½åˆ°GPU {gpu_id}")
        while True:
            try:
                task = task_queue.get(timeout=1.0)
                if task is None:
                    logger.info(f"GPU {gpu_id} æ”¶åˆ°é€€å‡ºä¿¡å·")
                    break
                
                task_id = task.get('task_id', 'unknown')
                logger.info(f"ğŸ¯ GPU {gpu_id} è¿›ç¨‹æ¥æ”¶åˆ°ä»»åŠ¡: {task_id[:8]}")
                logger.info(f"ğŸ“‹ ä»»åŠ¡è¯¦æƒ…: æç¤ºè¯='{task.get('prompt', '')[:50]}{'...' if len(task.get('prompt', '')) > 50 else ''}', æ¨¡å¼={task.get('mode', 'unknown')}")
                
                try:
                    logger.info(f"ğŸš€ GPU {gpu_id} å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id[:8]}")
                    result = model.generate(**task)
                    result['task_id'] = task_id
                    result['gpu_id'] = gpu_id
                    logger.info(f"âœ… GPU {gpu_id} ä»»åŠ¡ {task_id[:8]} å¤„ç†å®Œæˆï¼Œå‡†å¤‡å‘é€ç»“æœ")
                    result_queue.put(result)
                    logger.info(f"ğŸ“¤ GPU {gpu_id} ä»»åŠ¡ {task_id[:8]} ç»“æœå·²å‘é€åˆ°ç»“æœé˜Ÿåˆ—")
                except Exception as e:
                    logger.error(f"âŒ GPU {gpu_id} æ¨¡å‹æ¨ç†å¼‚å¸¸: {e}")
                    logger.error(traceback.format_exc())
                    error_result = {
                        "success": False,
                        "error": str(e),
                        "task_id": task_id,
                        "gpu_id": gpu_id
                    }
                    result_queue.put(error_result)
                    logger.error(f"ğŸ“¤ GPU {gpu_id} ä»»åŠ¡ {task_id[:8]} é”™è¯¯ç»“æœå·²å‘é€")
                
                # æ¨ç†åå¯é€‰æ¸…ç†
                gc.collect()
                logger.info(f"ğŸ§¹ GPU {gpu_id} ä»»åŠ¡ {task_id[:8]} å†…å­˜æ¸…ç†å®Œæˆ")
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"âŒ GPU {gpu_id} è¿›ç¨‹å¼‚å¸¸: {e}")
                logger.error(traceback.format_exc())
                break
    finally:
        if model is not None:
            model.unload()
        logger.info(f"GPU {gpu_id} å·¥ä½œè¿›ç¨‹é€€å‡º")

class GPUIsolationManager:
    """GPUéš”ç¦»ç®¡ç†å™¨ - ä½¿ç”¨å­è¿›ç¨‹å®ç°çœŸæ­£çš„GPUéš”ç¦»"""
    
    def __init__(self):
        self.processes: Dict[str, mp.Process] = {}
        self.result_queues: Dict[str, mp.Queue] = {}
        self.task_queues: Dict[str, mp.Queue] = {}
        self.process_configs: Dict[str, Dict[str, Any]] = {}  # å­˜å‚¨è¿›ç¨‹é…ç½®ç”¨äºé‡å¯
        self.is_running = True
        self.restart_attempts: Dict[str, int] = {}  # è®°å½•é‡å¯æ¬¡æ•°
        self.max_restart_attempts = 3  # æœ€å¤§é‡å¯æ¬¡æ•°
    
    def create_gpu_process(self, gpu_id: str, model_path: str, model_id: str) -> bool:
        """ä¸ºæŒ‡å®šGPUåˆ›å»ºéš”ç¦»è¿›ç¨‹"""
        try:
            task_queue = mp.Queue()
            result_queue = mp.Queue()
            process = mp.Process(
                target=gpu_worker_process,
                args=(gpu_id, model_path, model_id, task_queue, result_queue),
                name=f"gpu-worker-{gpu_id}"
            )
            process.start()
            process_key = f"{model_id}_{gpu_id}"
            self.processes[process_key] = process
            self.task_queues[process_key] = task_queue
            self.result_queues[process_key] = result_queue
            
            # ä¿å­˜è¿›ç¨‹é…ç½®ç”¨äºé‡å¯
            self.process_configs[process_key] = {
                "gpu_id": gpu_id,
                "model_path": model_path,
                "model_id": model_id
            }
            
            # åˆå§‹åŒ–é‡å¯è®¡æ•°
            self.restart_attempts[process_key] = 0
            
            logger.info(f"âœ… GPU {gpu_id} éš”ç¦»è¿›ç¨‹å·²åˆ›å»º (PID: {process.pid})")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºGPU {gpu_id} éš”ç¦»è¿›ç¨‹å¤±è´¥: {e}")
            return False
    
    def restart_gpu_process(self, process_key: str) -> bool:
        """é‡å¯æŒ‡å®šçš„GPUè¿›ç¨‹"""
        if process_key not in self.process_configs:
            logger.error(f"æ— æ³•é‡å¯è¿›ç¨‹ {process_key}ï¼šé…ç½®ä¸å­˜åœ¨")
            return False
        
        # æ£€æŸ¥é‡å¯æ¬¡æ•°
        if self.restart_attempts[process_key] >= self.max_restart_attempts:
            logger.error(f"è¿›ç¨‹ {process_key} é‡å¯æ¬¡æ•°å·²è¾¾ä¸Šé™ ({self.max_restart_attempts})ï¼Œåœæ­¢é‡å¯")
            return False
        
        config = self.process_configs[process_key]
        gpu_id = config["gpu_id"]
        
        logger.warning(f"ğŸ”„ å°è¯•é‡å¯GPU {gpu_id} è¿›ç¨‹ (ç¬¬ {self.restart_attempts[process_key] + 1} æ¬¡)")
        
        try:
            # æ¸…ç†æ—§è¿›ç¨‹
            if process_key in self.processes:
                old_process = self.processes[process_key]
                if old_process.is_alive():
                    old_process.terminate()
                    old_process.join(timeout=5.0)
                    if old_process.is_alive():
                        old_process.kill()
            
            # æ¸…ç†æ—§é˜Ÿåˆ—
            if process_key in self.task_queues:
                del self.task_queues[process_key]
            if process_key in self.result_queues:
                del self.result_queues[process_key]
            
            # åˆ›å»ºæ–°è¿›ç¨‹
            task_queue = mp.Queue()
            result_queue = mp.Queue()
            process = mp.Process(
                target=gpu_worker_process,
                args=(gpu_id, config["model_path"], config["model_id"], task_queue, result_queue),
                name=f"gpu-worker-{gpu_id}-restart"
            )
            process.start()
            
            # æ›´æ–°è¿›ç¨‹è®°å½•
            self.processes[process_key] = process
            self.task_queues[process_key] = task_queue
            self.result_queues[process_key] = result_queue
            self.restart_attempts[process_key] += 1
            
            logger.info(f"âœ… GPU {gpu_id} è¿›ç¨‹é‡å¯æˆåŠŸ (PID: {process.pid})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡å¯GPU {gpu_id} è¿›ç¨‹å¤±è´¥: {e}")
            return False
    
    def check_and_restart_dead_processes(self) -> Dict[str, bool]:
        """æ£€æŸ¥å¹¶é‡å¯æ­»äº¡çš„è¿›ç¨‹"""
        restart_results = {}
        
        for process_key, process in self.processes.items():
            try:
                if not process.is_alive():
                    logger.warning(f"æ£€æµ‹åˆ°æ­»äº¡è¿›ç¨‹ {process_key} (PID: {process.pid}, exitcode: {process.exitcode})")
                    
                    # å°è¯•é‡å¯
                    success = self.restart_gpu_process(process_key)
                    restart_results[process_key] = success
                    
                    if success:
                        logger.info(f"âœ… è¿›ç¨‹ {process_key} é‡å¯æˆåŠŸ")
                    else:
                        logger.error(f"âŒ è¿›ç¨‹ {process_key} é‡å¯å¤±è´¥")
                        
            except Exception as e:
                logger.error(f"æ£€æŸ¥è¿›ç¨‹ {process_key} çŠ¶æ€æ—¶å‡ºé”™: {e}")
                restart_results[process_key] = False
        
        return restart_results
    
    def submit_task(self, gpu_id: str, model_id: str, task: Dict[str, Any]) -> bool:
        """æäº¤ä»»åŠ¡åˆ°æŒ‡å®šGPU - å¼‚æ­¥æäº¤ï¼Œä¸ç­‰å¾…ç»“æœ"""
        process_key = f"{model_id}_{gpu_id}"
        
        if process_key not in self.task_queues:
            logger.error(f"GPU {gpu_id} è¿›ç¨‹ä¸å­˜åœ¨")
            return False
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜æ´»ç€
        if process_key not in self.processes:
            logger.error(f"GPU {gpu_id} è¿›ç¨‹è®°å½•ä¸å­˜åœ¨")
            return False
            
        process = self.processes[process_key]
        if not process.is_alive():
            logger.error(f"GPU {gpu_id} è¿›ç¨‹å·²æ­»äº¡ (PID: {process.pid}, exitcode: {process.exitcode})")
            
            # å°è¯•é‡å¯è¿›ç¨‹
            restart_success = self.restart_gpu_process(process_key)
            if restart_success:
                logger.info(f"GPU {gpu_id} è¿›ç¨‹å·²é‡å¯ï¼Œé‡æ–°æäº¤ä»»åŠ¡")
                # é‡æ–°è·å–è¿›ç¨‹å’Œé˜Ÿåˆ—
                process = self.processes[process_key]
                task_queue = self.task_queues[process_key]
            else:
                return False
        else:
            task_queue = self.task_queues[process_key]
        
        try:
            # å¼‚æ­¥æäº¤ä»»åŠ¡ï¼Œä¸ç­‰å¾…ç»“æœ
            task_id = task.get('task_id', 'unknown')
            logger.info(f"ğŸ“¤ å¼‚æ­¥æäº¤ä»»åŠ¡åˆ°GPU {gpu_id} (PID: {process.pid}): {task_id[:8]}")
            logger.info(f"ğŸ“‹ ä»»åŠ¡è¯¦æƒ…: æç¤ºè¯='{task.get('prompt', '')[:50]}{'...' if len(task.get('prompt', '')) > 50 else ''}', æ¨¡å¼={task.get('mode', 'unknown')}")
            
            task_queue.put(task, block=False)  # éé˜»å¡æäº¤
            logger.info(f"âœ… ä»»åŠ¡ {task_id[:8]} å·²æˆåŠŸæäº¤åˆ°GPU {gpu_id} ä»»åŠ¡é˜Ÿåˆ—")
            return True
            
        except queue.Full:
            error_msg = f"GPU {gpu_id} ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡"
            logger.error(error_msg)
            return False
        except Exception as e:
            error_msg = f"æäº¤ä»»åŠ¡åˆ°GPU {gpu_id} å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    def get_task_result(self, gpu_id: str, model_id: str, timeout: float = 300) -> Optional[Dict[str, Any]]:
        """ä»æŒ‡å®šGPUè·å–ä»»åŠ¡ç»“æœ - å¯é€‰ä½¿ç”¨"""
        process_key = f"{model_id}_{gpu_id}"
        
        if process_key not in self.result_queues:
            logger.error(f"GPU {gpu_id} ç»“æœé˜Ÿåˆ—ä¸å­˜åœ¨")
            return None
        
        result_queue = self.result_queues[process_key]
        
        try:
            # ç­‰å¾…ç»“æœ
            result = result_queue.get(timeout=timeout)
            logger.info(f"GPU {gpu_id} è·å–åˆ°ç»“æœ: {result.get('success', False)}")
            return result
            
        except queue.Empty:
            error_msg = f"GPU {gpu_id} è·å–ç»“æœè¶…æ—¶ ({timeout}ç§’)"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "gpu_id": gpu_id
            }
        except Exception as e:
            error_msg = f"ä»GPU {gpu_id} è·å–ç»“æœå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": str(e),
                "gpu_id": gpu_id
            }
    
    def get_gpu_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰GPUè¿›ç¨‹çŠ¶æ€"""
        status = {}
        
        for process_key, process in self.processes.items():
            try:
                is_alive = process.is_alive()
                status[process_key] = {
                    "pid": process.pid,
                    "alive": is_alive,
                    "exitcode": process.exitcode,
                    "name": process.name,
                    "daemon": process.daemon,
                    "restart_attempts": self.restart_attempts.get(process_key, 0),
                    "max_restart_attempts": self.max_restart_attempts
                }
                
                # å¦‚æœè¿›ç¨‹æ­»äº¡ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                if not is_alive:
                    logger.warning(f"è¿›ç¨‹ {process_key} å·²æ­»äº¡ (PID: {process.pid}, exitcode: {process.exitcode})")
                    
            except Exception as e:
                logger.error(f"æ£€æŸ¥è¿›ç¨‹ {process_key} çŠ¶æ€æ—¶å‡ºé”™: {e}")
                status[process_key] = {
                    "pid": "unknown",
                    "alive": False,
                    "exitcode": "unknown",
                    "error": str(e),
                    "restart_attempts": self.restart_attempts.get(process_key, 0),
                    "max_restart_attempts": self.max_restart_attempts
                }
        
        return status
    
    def shutdown(self):
        """å…³é—­æ‰€æœ‰GPUè¿›ç¨‹"""
        logger.info("æ­£åœ¨å…³é—­GPUéš”ç¦»ç®¡ç†å™¨...")
        
        # å‘é€é€€å‡ºä¿¡å·
        for process_key, task_queue in self.task_queues.items():
            try:
                task_queue.put(None)  # é€€å‡ºä¿¡å·
            except:
                pass
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        for process_key, process in self.processes.items():
            try:
                process.join(timeout=10.0)
                if process.is_alive():
                    process.terminate()
                    process.join(timeout=5.0)
                    if process.is_alive():
                        process.kill()
            except Exception as e:
                logger.warning(f"å…³é—­è¿›ç¨‹ {process_key} æ—¶å‡ºé”™: {e}")
        
        logger.info("GPUéš”ç¦»ç®¡ç†å™¨å·²å…³é—­")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•GPUéš”ç¦»
    manager = GPUIsolationManager()
    
    # åˆ›å»ºGPUè¿›ç¨‹
    gpu_ids = ["0", "1", "2", "3"]
    from config import Config
    model_paths = Config.get_model_paths()
    model_path = model_paths.get("flux1-dev", "/path/to/flux1-dev")
    
    for gpu_id in gpu_ids:
        manager.create_gpu_process(gpu_id, model_path, "flux1-dev")
    
    # æäº¤æµ‹è¯•ä»»åŠ¡
    test_task = {
        "task_id": "test_001",
        "prompt": "A beautiful landscape",
        "height": 1024,
        "width": 1024,
        "seed": 42
    }
    
    result = manager.submit_task("0", "flux1-dev", test_task)
    print(f"æµ‹è¯•ç»“æœ: {result}")
    
    # å…³é—­ç®¡ç†å™¨
    manager.shutdown() 